This file was created with JabRef 2.2.
Encoding: ISO8859_1

@ARTICLE{Biris1999,
  author = {Biris, E. and Shen, Q.},
  title = {{Automatic modelling using Bayesian networks for explanation generation}},
  journal = {Proceedings of the 13th International Workshop on Qualitative Reasoning
	about Physical Systems},
  year = {1999},
  pages = {19--26},
  abstract = {The task of generating informative explanations in industrial training
	involves automated formulation of system models with respect to the
	varying levels of the trainees' knowledge. Compositional Modelling
	provides a useful basis upon which to structure a suite of models
	that may reflect different complexities of the systems being modelled.
	However, additional inferences are required in order to select appropriate
	model fragments to form a coherent system model that is suitable
	for a given trainee's degree of expertise. This paper presents a
	novel approach to perform such inferences by the use of Bayesian
	networks. The work is implemented and typical experimental results
	are given.}
}

@ARTICLE{Callaway1997,
  author = {Callaway, C.B. and Lester, J.C.},
  title = {{Dynamically improving explanations: A revision-based approach to
	explanation generation}},
  journal = {Proceedings of the Fifteenth International Joint Conference on Artificial
	Intelligence},
  year = {1997},
  pages = {952--58},
  abstract = {Recent years have witnesseed rapid progress in explanation generation.
	 Despite these advances, the quality of prose produced by explanation
	generators warrants significant improvement.  Revision-based explanation
	generation offers a promising means for improving explanations at
	runtime.  in contrast to single-draft explanation generation architectures,
	a revision-based generator could dynamically create, evaluate, and
	refine multiple drafts of explanations.  However, because of the
	inherent complexity of revision, previous multisentential revision-based
	approaches have not scaled up.  We have developed a scalable revision-based
	model of explanation generation that dynamically improves multi-sentential
	explanations.  By operating on abstract discourse plans encoded in
	a minimalist representation, it combats both the conceptual complexities
	and the efficiency problems posed by revision.  This approach has
	been implemented in REVISOR, a unification-based revision system.
	 Evaluations of REVISOR's performance in generating a corpus of extended
	multi-sentential scientific explanations yielded encouraging results.},
  url = {http://homepages.inf.ed.ac.uk/ccallawa/papers/revisor-ijcai-97.pdf}
}

@ARTICLE{Karsenty1995,
  author = {Karsenty, L. and Br{\'e}zillon, P.},
  title = {{Cooperative problem solving and explanation}},
  journal = {International Journal of Expert Systems With Applications},
  year = {1995},
  volume = {4},
  pages = {445--462},
  __markedentry = {[bogart]},
  abstract = {Recent studies have pointed out several limitations of expert systems
	regarding user needs, and have introduced the concepts of cooperation
	and joint cognitive systems in the focus of AI. While research on
	explanation generation by expert systems has been widely developed,
	there has been little consideration of explanation in relation to
	cooperative systems. Our aim is to elaborate a conceptual framework
	for studying explanation in cooperation. This work relies heavily
	on the study of human-human cooperative dialogues. We present our
	results according to two dimensions, namely, the relation between
	explanation and problem solving, and the explanation process. Finally,
	we discuss the implications of these results for the design of cooperative
	systems.}
}

@INPROCEEDINGS{Kukich1985,
  author = {Karen Kukich},
  title = {Explanation structures in XSEL},
  booktitle = {Proceedings of the 23rd annual meeting on Association for Computational
	Linguistics},
  year = {1985},
  pages = {228--237},
  address = {Morristown, NJ, USA},
  publisher = {Association for Computational Linguistics},
  abstract = {Expert systems provide a rich testbed from which to develop and test
	techniques for natural language processing.  These systems caputre
	the knowledge needed to solve real-world problems in their respective
	domains, and that knowledge can and should be exploited for testing
	computational procedures for natural language processing.  Parsing,
	semantic interpretation, dialog monitoring, discourse organization,
	and text generation are just a few of the language processing problems
	that might take advantage of the pre-structured semantic knowledge
	of an expert system.  In particular, the need for explanation generation
	facilities for expert systems provides an opportunity to explore
	the relationships between the underlying knowledge structures needed
	for automated reasoning and those needed for natural langauge processing.
	 One such exploration was the development of an explanation generator
	for XSEL, which is an expert system that helps a salesperson in producing
	a purchase order for a computer system.  This paper describes a technique
	called "link-dependent message generation" that forms the basis for
	explanation generation in XSEL.},
  doi = {http://dx.doi.org/10.3115/981210.981238},
  location = {Chicago, Illinois}
}

@ARTICLE{Lester1997,
  author = {Lester, J.C. and Porter, B.W.},
  title = {{Developing and Empirically Evaluating Robust Explanation Generators:
	The KNIGHT Experiments}},
  journal = {Computational Linguistics},
  year = {1997},
  volume = {23},
  pages = {65--101},
  number = {1},
  abstract = {To explain complex phenomena, an explanation system must be able to
	select information from a formal representation of domain knowledge,
	organize the selected information into multisentential discourse
	plans, and realize the discourse plans in text. Although recent years
	have witnessed significant progress in the development of sophisticated
	computational mechanisms for explanation, empirical results have
	been limited. This paper reports on a seven-year effort to empirically
	study explanation generation from semantically rich, large-scale
	knowledge bases. In particular, it describes KNIGHT, a robust explanation
	system that constructs multisentential and multi-paragraph explanations
	from the Biology Knowledge Base, a large-scale knowledge base in
	the domain of botanical anatomy, physiology, and development. We
	introduce the Two-Panel evaluation methodology and describe how KNIGHT's
	performance was assessed with this methodology in the most extensive
	empirical evaluation conducted on an explanation system. In this
	evaluation, KNIGHT scored within "half a grade" of domain experts,
	and its performance exceeded that of one of the domain experts.}
}

@ARTICLE{Maybury1992,
  author = {Maybury, M.T.},
  title = {{Communicative acts for explanation generation}},
  journal = {International Journal of Man-Machine Studies},
  year = {1992},
  volume = {37},
  pages = {135--172},
  number = {2},
  abstract = {Knowledge-based systems that interact with humans often need to define
	their terminology, elucidate their behavior or support their recommendations
	or conclusions. In general, they need to explain themselves. Unfortunately,
	current computer systems, if they can explain themselves at all,
	often generate explanations that are unnatural, ill-connected or
	simply incoherent. They typically have only one method of explanation
	which does not allow them to recover from failed communication. At
	a minimum, this can irritate an end-user and potentially decrease
	their productivity},
  publisher = {Academic Press Ltd. London, UK, UK}
}

@ARTICLE{Moore1989,
  author = {Moore, J.D.},
  title = {{Responding to ‘Huh?’: Answering vaguely-articulated follow-up
	questions}},
  journal = {Proceedings of the Conference on Human Factors in Computing Systems},
  year = {1989},
  pages = {91--96},
  abstract = {Expert and advice-giving systems produce complex multi-sentential
	responses to users' queries.  Results from analyses of novice/expert
	dialogues indicate that novices often do not understand and expert's
	response and rarely ask a well-formulated follow-up question.  Thus
	systems must be able to provide further information in response to
	vaguely articulated questions.  However, current systems cannot clarify
	misunderstood explanations or elaborate on previous explanations.
	 In this paper we describe an approach to explanation generation
	that expands a system's explanatory capabilities and enables the
	production of clarifying or elaborating explanations in response
	to follow-up questions or indication that the explanation was not
	understood.}
}

@ARTICLE{Moore1991,
  author = {Moore, JD and Swartout, WR},
  title = {{A Reactive Approach to Explanation: Taking the User’s Feedback
	into Account}},
  journal = {Natural Language Generation in Artificial Intelligence and Computational
	Linguistics},
  year = {1991},
  pages = {3--47}
}

@ARTICLE{Moulin2002,
  author = {Moulin, B. and Irandoust, H. and B{\'e}langer, M. and Desbordes,
	G.},
  title = {{Explanation and Argumentation Capabilities: Towards the Creation
	of More Persuasive Agents}},
  journal = {Artificial Intelligence Review},
  year = {2002},
  volume = {17},
  pages = {169--222},
  number = {3},
  __markedentry = {[bogart]},
  abstract = {During the past two decades many research teams have worked on the
	enhancement of the explanation capabilities of knowledge-based systems
	and decision support systems. During the same period, other researchers
	have worked on the development of argumentative techniques for software
	systems. We think that it would be interesting for the researchers
	belonging to these different communities to share their experiences
	and to develop systems that take advantage of the advances gained
	in each domain.
	
	We start by reviewing the evolution ofexplanation systems from the
	simple reasoning traces associated with early expert systems to recent
	research on interactive andc ollaborative explanations. We then discuss
	the characteristics of critiquing systems that test the credibility
	of the user's solution. The rest of the paper deals with the different
	application domains that use argumentative techniques. First, we
	discuss how argumentative reasoning can be captured by a generals
	tructure in which a given claim or conclusion is inferred from a
	set of data and how this argument structure relates to pragmatic
	knowledge, explanation production and practical reasoning. We discuss
	the role of argument in defeasible reasoning and present some works
	in the new field of computer-mediated defeasible argumentation. We
	review different application domains such as computer-mediated communication,
	design rationale, crisis management and knowledge management, in
	which argumentation support tools are used. We describe models in
	which arguments are associated to mental attitudes such as goals,
	plans and beliefs. We present recent advances in the application
	of argumentative techniques to multi-agent systems. Finally, we propose
	research perspectives for the integration of explanation and argumentation
	capabilities in knowledge-based systems and make suggestions for
	enhancing the argumentation and persuasion capabilities of software
	agents.},
  publisher = {Springer}
}

@ARTICLE{Neumann1997,
  author = {Neumann, G.},
  title = {{Applying explanation-based learning to control and speeding-up natural
	language generation}},
  journal = {Proceedings of the eighth conference on European chapter of the Association
	for Computational Linguistics},
  year = {1997},
  pages = {214--221},
  abstract = {This paper presents a method for the automatic extraction of subgrammars
	to control and speeding-up natural language generation NLG. The method
	is based on explanation-based learning EBL. The main advantage for
	the proposed new method for NLG is that the complexity of the grammatical
	decision making process during NLG can be vastly reduced, because
	the EBL method supports the adaption of a NLG system to a particular
	use of a language.},
  publisher = {Association for Computational Linguistics Morristown, NJ, USA}
}

@comment{jabref-meta: selector_journal:}

@comment{jabref-meta: selector_author:kandogan;}

@comment{jabref-meta: selector_keywords:}

@comment{jabref-meta: selector_publisher:}

@comment{jabref-meta: groupsversion:3;}

@comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:Explanations\;0\;Biris1999\;Callaway1997\;Karsenty1995
\;Kukich1985\;Lester1997\;Maybury1992\;Moore1989\;Moore1991\;Moulin200
2\;Neumann1997\;;
}

