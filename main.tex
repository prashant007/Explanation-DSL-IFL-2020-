\NeedsTeXFormat{LaTeX2e}

\documentclass{jfp}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{nicefrac}
% \usepackage{array}
% \usepackage{mathpartir}
% \usepackage[utf8]{inputenc}
% \usepackage{color, colortbl}
% \usepackage{float}

\usepackage[dvipsnames]{xcolor}
\usepackage{minted}
\usepackage{stackengine}
\usepackage{subcaption}
% \usepackage{etoolbox}
% \BeforeBeginEnvironment{minted}{\vspace{0pt plus 1pt minus 2pt}}
% \AfterEndEnvironment{minted}{\vspace{0pt plus 1pt minus 2pt}}

\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{graphicx}
\definecolor{processblue}{cmyk}{0.96,0,0,0}
\newcommand{\NOTE}[2][gray]{\smallskip\noindent
  \colorbox{#1!30}{\parbox{.98\linewidth}{{\small\textbf{#2}}}}
}


\usepackage{natbib}
\bibliographystyle{jfp}
% \setcitestyle{authoryear, open={(},close={)}}


% \theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}


\newcommand{\norm}[1]{\ensuremath{\overline{#1}}}
% \newcommand{\norm}[1]{\ensuremath{\underline{#1}}}
\newcommand{\nR}{\norm{R}}
\newcommand{\nT}{\norm{T}}
\newcommand{\nQ}{\norm{Q}}
\newcommand{\nr}{\norm{r}}
\newcommand{\nv}{\norm{v}}
\newcommand{\nw}{\norm{w}}
\newcommand{\seq}[3]{\ensuremath{\overline{#3}^{#1:1..#2}}}



%\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand{\SP}[1][s]{\ensuremath{\textit{SP}_{#1}}}		   
\newcommand{\VD}{\textsc{vd}}		   
\newcommand{\DVD}{\textsc{dvd}}		   
\newcommand{\prog}[1]{\mintinline[fontsize=\footnotesize]{haskell}{#1}}
\newcommand{\prg}[2][blue]{\color{#1}\texttt{{\footnotesize #2}}\color{black}}


\newminted{haskell}{frame=none,framesep=0mm,xleftmargin=\parindent,samepage=true,baselinestretch=1,fontsize=\footnotesize}
\newminted[haskellfig]{haskell}{frame=bottomline,framesep=0mintmm,samepage=true,baselinestretch=1,fontsize=\footnotesize}


\setlength\partopsep{-\topsep}
\addtolength\partopsep{-\parskip}
\addtolength\partopsep{3mm}
			   

% some general LaTeX settings			   
\sloppy
\sloppypar

% to typeset URLs, URIs, and DOIs
% \usepackage{url}
% \def\UrlFont{\rmfamily}
% \usepackage[hyphens]{url}
% \renewcommand{\UrlFont}{\ttfamily\small}


\begin{document}
\journaltitle{JFP}
\cpr{Cambridge University Press}
\doival{10.1017/xxxxx}

\label{firstpage}
\totalpg{\pageref{lastpage}}
\jnlDoiYr{2020}

% \title{Explanations for Dynamic Programming\thanks{This work is partially supported by DARPA under the grant N66001-17-2-4030 and by the National Science Foundation under the grant CCF-1717300.}}

% \def\thetitle{A DSL for Hierarchical Explanations}
% \def\thetitle{A DSL for Explanatory AHP Decision Making}
% \def\thetitle{A DSL for Explanatory [Multi-Attribute] Decision Making}
% \def\thetitle{A DSL for AHP Decision Making with Explanations}
\def\thetitle{AHP Decision Making: Functionally and with Explanations}


\title{\thetitle}
\righttitle{\thetitle}
\lefttitle{M.\ Erwig and P.\ Kumar}

\begin{authgrp}
\author{Martin Erwig and Prashant Kumar}
\authorrunning{M.\ Erwig and P.\ Kumar}
\affiliation{Oregon State University \\
(\email{[erwig, kumarpra]@oregonstate.edu})}
\end{authgrp}

%\received{20 March 1995; revised 30 September 1998}

\begin{abstract}
%
\end{abstract}

\maketitle


\noindent
%
% \fbox{\textbf{Conflicts of Interest: None}}

\section{Introduction}

Multi-attribute decision making (MADM) is an important component of modern decision sciences~\citep{MADMSurveys}.  It comprises a number of different techniques, one of which is the widely used \emph{Analytic Hierarchy Process} (AHP)~\citep{SAATY1987161} which allows aspects of the decision making process to be decomposed and arranged in a hierarchy. 

The theory and methods of MADM have been extensively applied in many areas, ranging from engineering projects, economics, public administration, to management and military projects.
%
For example, in 1986 the Institute of Strategic Studies in Pretoria, a government-backed organization, used AHP to analyze the conflict in South Africa and recommended actions ranging from the release of Nelson Mandela to the removal of apartheid and the granting of full citizenship and equal rights to the black majority~\citep{articleSaatySA}. All the recommendations were implemented within a short time. Another high-profile example is the use if AHP in the 1995 US/China conflict over Chinese illegal copying of music, video, and software~\citep{SAATY2001243}. An AHP analysis involving four hierarchies for benefits, costs, opportunities, and risks showed, surprisingly, that it was much better for the US \emph{not} to sanction China. The result of the study predicted what happened. Shortly after the study was complete, the U.S.\ awarded China the most-favored nation status and didn't sanction it.
%
In the domain of business, the Xerox Corporation has used the AHP to allocate close to a billion dollars to its research projects~\citep{Saaty2002DECISIONMW}, and IBM used AHP in 1991 in designing its successful mid-range AS 400 computer~\citep{TANG199222}. IBM won the prestigious Malcolm Baldrige award for Excellence for that effort, the United State's highest presidential honor for performance excellence.

The programming language support for AHP is not commensurate with the important role it plays in decision making in today's world. Most programming languages either provide minimal or no support for AHP. Even the small number of AHP libraries offered by the various programming languages require the AHP problems to be encoded in special formats like JSON, making it even more inconvenient for end users. 
%
In this paper we address this shortcoming by introducing an embedded Haskell DSL that facilitates a convenient, high-level formulation of AHP problems. In addition to solving AHP problems our DSL can also produce explanations of why a found optimal solution is better than its alternatives.

\NOTE{We need to point out the FP-specific parts of the DSL solution/implementation and emphasize contributions of the paper. For example, talking about how matrix multiplication is represented by function/mapping refinement/extension.}


\NOTE{Also, point out the flexibility offered by our DSL to dynamically adapt the data and valuations and compare it with how that would have to be done in the core AHP approach. Repeat in conclusion.}

We introduce the problem domain of multi-attribute decision making and our basic representation with a simple (non-hierarchical) example in Section \ref{sec:flat}.
%
In Section \ref{sec:ahp} we will then ...

\NOTE{Talk about matrices, matrix multiplication and how we represent this as functions.}


... MDS, explanations 

... related work.



% \section{A Simple Example (need better title)}
\section{Evaluating Non-Hierarchical Data}
\label{sec:flat}

Imagine you want to buy a new car and are trying to decide between, say, a Honda CRV and a BMW X1. If the comparison is based on only one attribute, such as price or fuel economy, the decision is easy, at least if the attribute is measured with values from a type with a total order. More realistically, however, the decision must take into account several different attributes that evaluate the choices along different dimensions. 
%
Let's assume that in our example we want to base our decision on price, fuel economy, and safety rating, which are all measured in different units (money, miles-per-gallon, a number between 1 and 10, respectively).
%
An approach that takes into account all the attributes must facilitate the comparison of values in different domains, which can be achieved by mapping attributes into one common domain.

As a first step we can collect the relevant information in a data structure that maps cars to records of their features and corresponding values. To this end, we define data types for the different features on which to collect information and the cars that we plan to evaluate.

\begin{haskellcode}
data Car     = Honda | BMW | Toyota
data Feature = Price | MPG | Safety 
\end{haskellcode}

\noindent
%
Using a smart constructor \prog{info} we can construct a mapping of cars to feature records, which are themselves mappings from attroibutes to numeric values; the arrow \prog{-->} is simply syntactic sugar for building pairs, see Figure \ref{fig:info}.

\begin{haskellcode}
carFeatures :: Info Car Feature
carFeatures = info [Honda --> [Price --> 34000, MPG --> 30, Safety --> 9.8],
                    BMW   --> [Price --> 36000, MPG --> 33, Safety --> 9.1]]
\end{haskellcode}

% \NOTE{So far we have only shown some parts of the implementation of the DSL. We have to decide what details to present and where to present them.}

\begin{figure}[t]
\begin{haskellcode}
data Rec    a = Rec  {unRec  :: Map a Double}
data Info o a = Info {unInfo :: Map o (Rec a)}

info :: (Ord o,Ord a) => [(o,[(a,Double)])] -> Info o a
(!)  :: Eq o          => Info o a -> o      -> Rec a
diff :: (Ord o,Ord r) => Info o r -> o -> o -> Rec r
\end{haskellcode}
% \begin{haskellcode}
% data Rec    a = Rec  {unRec  :: Map a Double}
% data Info o a = Info {unInfo :: Map o (Rec a)}
%
% type Nums a = [(a,Double)]
%
% info :: (Ord o,Ord a) => [(o,Nums a)] -> Info o a
% info ons = Info $ fromList [(o,mkRec ns) | (o,ns) <- ons]
%
% (-->) :: a -> v -> (a,v)
% x --> y = (x,y)
%
% select :: Ord o => o -> Info o a -> Rec a
% select o = fromJust . lookup o . unInfo
%
% (!) :: Eq o => Info o a -> o -> Rec a
% (!) = flip select
%
% diff :: (Ord o,Ord r) => Info o r -> o -> o -> Rec r
% diff i o1 o2 = i!o1 - i!o2
%
% \end{haskellcode}
\caption{Data Representation via maps (based on \prg{Data.Map}).}
\label{fig:info}
\end{figure}

\noindent
%
With this representation we can already perform some interesting computations. Since records can be defined as instances of \prog{Num}, we can employ subtraction to define an operation for comparing records of individual objects.

\begin{haskellcode}
> diff carFeatures Honda BMW
{Price -> -2000.00, MPG -> -3.00, Safety -> 0.70}
\end{haskellcode}

\noindent
%
The comparison shows that while the Honda is cheaper and has a slightly better safety rating, it's fuel economy is worse.
%
Does that make the Honda or the BMW a better choice? It depends on how we value the different attributes and the corresponding differences in their values. To facilitate a better comparison we first normalize all attributes by mapping them to values in a common numeric interval\footnote{The AHP method uses the intervall [0..1], but for better readability we use the range 0 to 100 and remove the syntactically burdensome ``\prog{0.}'' prefixes, which also makes 3 or 4 digits of precision more palatable.} such as $0..100$ where larger means ``better.'' We can do this by using the function \prog{valuation}, see Figure \ref{fig:val}.
%
% The resulting type \prog{Val} is a type synonym for \prog{Info} but carries only normalized values.

\begin{haskellcode}
> valuation carFeatures
{Honda -> {Price -> 51.43, MPG -> 47.62, Safety -> 51.85},
 BMW   -> {Price -> 48.57, MPG -> 52.38, Safety -> 48.15}}
\end{haskellcode}

\noindent
%
Based on the normalized values we can compute the total values for the cars to immediately see how they compare.

\begin{haskellcode}
> total $ valuation carFeatures
{Honda -> 150.9, BMW -> 149.1}
\end{haskellcode}

\noindent
%
Of course, all these considerations assume that each attribute is weighed equally, which is not really a realistic assumption.
%
It is not difficult to implement functions for computing different weighted averages of an attribute valuation. However, a more systematic approach for doing so in the context of the AHP methodology is to modify the valuation by multiplying it with a weight vector.
%
We will explain this in the next section.


\noindent
%
The reader may have noticed the following curiosity about how the attributes have been turned into valuations: Whereas higher MPG values lead to higher valuations, higher prices lead to lower valuations, which is what we want (a high price is bad, a high MPG is good).
%
Since this semantic information cannot be inferred automatically, we have to provide it explicitly, which we do by assigning a so-called \emph{valence} to each attribute indicating whether large numbers actually mean a positive value contribution, which is the case for \prog{MPG} and \prog{Safety} but not for \prog{Price}.

\begin{haskellcode}
instance Valence Feature where
  valence Price = False
  valence _     = True
\end{haskellcode}

\noindent
%
Based on the valence information, valuation replaces each value $v_{ij}$ in a record 
%
$R_i = \{A_1 \mapsto v_{i1}, \ldots, A_k \mapsto v_{ik}\}$ 
%
that is part of a mapping 
%
$M = \{O_1 \mapsto R_1, \ldots, O_n \mapsto R_n\}$ 
%
by its normalized value $\nv_{ij}$, which is defined as follows.\footnote{We write \norm{v}, \norm{R}, and \norm{M} for normalized values, records containing normalized values, and mappings that carry normalized records, respectively.}
%
% --- OR:
%
% Based on the valence information, valuation replaces each value $v_{ij}$ in a record 
% %
% $R_i = \{\seq{j}{k}{A_j \mapsto v_{ij}}\}$ 
% %
% that is part of a mapping 
% $M = \{\seq{i}{n}{O_i \mapsto R_i}\}$ 
% %
% by its normalized value $\nv_{ij}$, which is defined as follows.
%
% --- OR:
%
% Based on the valence information, valuation replaces each value $v_{ij}$ in a record 
% %
% $r_i = \{\seq{j}{k}{a_j \mapsto v_{ij}}\}$ 
% %
% that is part of a mapping 
% $m = \{\seq{i}{n}{o_i \mapsto r_i}\}$ 
% %
% by its normalized value $\nv_{ij}$, which is defined as follows.
%
% --- END OR
%
If attribute $A_j$ has positive valence $(A_j^+)$, then $v_{ij}$ is normalized with respect to the sum of all values $v_{1j}, \ldots, v_{nj}$ used for that attribute. Otherwise $(A_j^-)$, normalization uses the reciprocals of the values.
%
\begin{align*}
&\norm{v}_{ij} = \frac{v_{ij}}{\sum_{l=1}^{n} v_{lj}} \times 100
\quad (A_j^+)
&\norm{v}_{ij} &= \frac{\nicefrac{1}{v_{ij}}}{\sum_{l=1}^{n} \nicefrac{1} {v_{lj}}} \times 100
\quad (A_j^-)
\end{align*}
%
The multiplication by 100 scales the result to a number between 0 and 100.
%
The implementation of \prog{valuation} that implements this definition can be found in the accompanying code.

The normalization step achieves first and foremost an unbiased comparison of the attribute differences. Is the price difference of \$2,000 more significant than a difference of 3 miles-per-gallon fuel efficiency?
%
By using the \prog{diff} function on the normalized records we can infer from comparing the absolute values that the answer is ``no.'' 

% \begin{haskellcode}
% > diff (valuation carFeatures) Honda BMW
% {Price -> 2.86, MPG -> -4.76, Safety -> 3.60}
% \end{haskellcode}
%
\begin{haskellcode}
> let vd = diff (valuation carFeatures) Honda BMW
{Price -> 2.86, MPG -> -4.76, Safety -> 3.60}
\end{haskellcode}


\begin{figure}[t]
\begin{haskellcode}
class Ord a => Valence a where
  valence :: a -> Bool
  valence _ = True

class (Bounded a,Enum a,Ord a) => Set a where
  members :: [a]
  members = enumFromTo minBound maxBound

type Val o a = Info o a

valuation :: (Ord o,Set a,Valence a) => Info o a -> Val o a
total     :: Ord a => Val o a -> Rec o
\end{haskellcode}
\caption{Valuations. The \prg{Set}\ class defines a function \prg{members}\ to enumerate all elements of an instance type, which is needed for iterations in several normalization functions. All attribute types must implement \prg{Set}.}
\label{fig:val}
\end{figure}


\noindent
%
Note that the values for the attributes are based on the current data, which consists only of 2 cars. If we add more cars, the total available value of 100 for each attribute will be split among the three cars and the differences between two specific cars will inevitably become smaller. 
%
A more subtle effect is that the relative importance of an attribute can change as well. For example, consider the following addition to the car comparison.

\begin{haskellcode}
threeCars :: Info Car Feature
threeCars = carFeatures `union`
            info [Toyota --> [Price --> 27000, MPG --> 30, Safety --> 9.4]]
\end{haskellcode}

\noindent
%
The valuation yields, unsurprisingly, smaller values for each attribute.

\begin{haskellcode}
> valuation threeCars
{Honda ->  {Price -> 31.2, MPG -> 32.3, Safety -> 34.6},
 BMW ->    {Price -> 29.5, MPG -> 35.5, Safety -> 32.2},
 Toyota -> {Price -> 39.3, MPG -> 32.3, Safety -> 33.2}}
\end{haskellcode}

\noindent
%
But more importantly, if we again compare the significance of the attributes, we see that the price difference between Honda and BMW, which hasn't changed, has lost in significance relative to the MPG difference.

\begin{haskellcode}
> let vd3 = diff (valuation threeCars) Honda BMW
{Price -> 1.73, MPG -> -3.23, Safety -> 2.47}
\end{haskellcode}

\noindent
%
The price difference was about 60\% ($\approx2.9/4.8$) of the value that MPG contributed when we looked at 2 cars. Since the addition of the overall price range has increased through the addition of the third car while the safety rating range remained the same, the relative value has dropped to about 53\% ($\approx2.7/3.2$).
%
To get a precise picture of the impact each attribute has on the overall value difference, we can compute what we call their
%
\emph{value difference impact} (\emph{VDI}), and we can observe how the relative impacts change for a comparison of two cars when data is added, even if the data of the compared cars doesn't change.

\begin{haskellcode}
> impact vd
{Price -> 25%, MPG -> 42%, Safety -> 33%}

> impact vd3
{Price -> 23%, MPG -> 43%, Safety -> 33%}
\end{haskellcode}

\noindent
%
Computing the impact of attributes is a special case of focusing in a multi-dimensional comparison on the contributions of attributes from a specific dimension. 
%
We will extend our example by additional attribute dimensions in Section \ref{sec:nested} and revisit the question of attribute impact and focus in Section \ref{sec:trans}.
%
In general, the relative contribution of different attributes to the overall valuation of individual items helps explain the rankings that are computed based on these valuations. We will talk more about explanation of comparisons and ranking decisions later in Section \ref{sec:mds}.

\NOTE{What's the best name here? ``factorizing'' is OK, but ``grouping'' or even ``projecting'' might be more accurate.}



% \section{AHP (need better title)}
\section{Refined Evaluation Through Multi-Dimensional Attributes}
\label{sec:ahp}
\label{sec:nested}

The basic form of valuation distributes 100 value points across $k$ alternatives for each of $n$ attributes, that is, the total number of points is $100n$, each attribute will on average have $100/k$ points, and each alternative will have on average $100n/k$ points. We have seen a few examples in the previous section.
%
This representation views a data set through the lens of comparing $n$ independent attributes. 
%
When we want to combine all attributes into one value to determine the best alternative, we can achieve this, as shown in the previous section, by simply extracting the total value with the function \prog{total}, but we can also do this more systematically by combining the three attributes into one.

This operation is a special case of refining an attribute dimension of type \prog{a} by an attribute dimension of another type \prog{b}. In our example we want to refine the feature attributes by weights. 
%
To better explain the approach let us assume that we want to entertain different weightings (from which we can later select a specific one). Specifically, in addition to our own personal weighting scheme we also consider how experts weight the attributes. 
%
To this end, we first define a data type for the new attribute dimension capturing different opinions about what weighting scheme to use.

\begin{haskellcode}
data Opinion = Personal | Expert
\end{haskellcode}

\noindent
%
We can then record the different preferences about how to weight attributes in the same way as the data about car features.

\begin{haskellcode}
featureOpinions :: Info Feature Opinion
featureOpinions = info [Price  --> [Personal --> 5, Expert --> 3],
                        MPG    --> [Personal --> 3, Expert --> 5],
                        Safety --> [Personal --> 2, Expert --> 2]]
\end{haskellcode}

\noindent
%
The weightings can be applied to the feature data by multiplying the two nested mappings. This essentially amounts to a matrix multiplication (which is how it is defined in AHP).
%
To prepare the extension we convert the valuation of car features into one that wraps the feature records in a singleton tuple. This requirement facilitates the overloading of the \prog{extendBy} function for arbitrary tuples, see Figure \ref{fig:multi}.

\begin{haskellcode}
featureVal :: Val Car (OneTuple Feature)
featureVal = mkOneTuple (valuation carFeatures)

carOpinions :: Val Car (Feature,Opinion)
carOpinions = featureVal `extendBy` featureOpinions
\end{haskellcode}


\begin{figure}[t]
\begin{haskellcode}
class SubDim a b | a -> b where 
  proj :: a -> b

instance SubDim (a,b) a where proj = fst
instance SubDim (a,b) b where proj = snd
...

extendBy :: (Ord o,Ord b,Valence c,Set c,Ord d,Tuple a c d,SubDim a b) => 
             Val o a -> Info b c -> Val o d
only   :: (Eq b,SubDim a b) => b -> Info o a -> Info o a
except :: (Eq b,SubDim a b) => b -> Info o a -> Info o a
\end{haskellcode}
\caption{Functions for working with multi-dimensional attributes. \textbf{We also must explain the other classes \prg{Tuple}\ and \prg{SubDim}\ ...}.}
\label{fig:multi}
\end{figure}

The values for the two attributes \prog{Personal} and \prog{Expert} refine the values of the \prog{Feature} attributes. The \prog{Opinion} dimension also acts as a summary of the \prog{Feature} dimension. 

\begin{haskellcode}
> carOpinions
{Honda -> {(Price,Personal)  -> 25.71, (Price,Expert)  -> 15.43
           (MPG,Personal)    -> 14.29, (MPG,Expert)    -> 23.81,
           (Safety,Personal) -> 10.37, (Safety,Expert) -> 10.37},
 BMW ->   {(Price,Personal)  -> 24.29, (Price,Expert)  -> 14.57,
           (MPG,Personal)    -> 15.71, (MPG,Expert)    -> 26.19,
           (Safety,Personal) -> 9.63,  (Safety,Expert) -> 9.63}}
\end{haskellcode}

\noindent
%
The valuation \prog{carOpinions} distributes 100 points as before across 2 car alternatives, but now for only 2 attributes, \prog{Personal} and \prog{Expert}, which can be seen when computing the totals, which now sum to 200.

\begin{haskellcode}
> total carOpinions
{Honda -> 99.98, BMW -> 100.02}
\end{haskellcode}

\noindent
%
Extending a valuation 
%
$\norm{M} = \{O_1 \mapsto \nR_1, \ldots, O_n \mapsto \nR_n\}$
%
means to refine each record $\norm{R}_i= \{A_1 \mapsto \nv_{i1}, \ldots, A_k \mapsto \nv_{ik}\}$ according to a mapping $N = \{A_1 \mapsto S_1, \ldots, A_k \mapsto S_k\}$ that carries for each attribute $A_j$ a record $S_j$, which itself consists of $l$ attributes from a generally different domain, that is, 
%
$S_j = \{B_1 \mapsto w_{j1}, \ldots, B_l \mapsto w_{jl}\}$.
%
In the first step we can normalize $N$ by normalizing each record $S_j$ in the same way as described earlier, which yields
%
$\norm{S}_j = \{B_1 \mapsto \nw_{j1}, \ldots, B_l \mapsto \nw_{jl}\}$.
%
%
% --- OR:
%
% Extending a valuation 
% %
% $\norm{M} = \{\seq{i}{n}{O_i \mapsto \nR_i}\}$
% %
% means to decompose each record 
% %
% $\nR_i= \{\seq{j}{k}{A_j \mapsto \nv_{ij}}\}$ 
% %
% according to a mapping 
% %
% $N = \{\seq{j}{k}{A_j \mapsto S_j}\}$ that carries for each attribute $A_j$ a record $S_j$, which itself consists of $l$ attributes from a generally different domain, that is, 
% %
% $S_j = \{\seq{l}{m}{B_l \mapsto w_{jl}}\}$.
% %
% In the first step we can normalize $N$ by normalizing each record $S_j$ in the same way as described earlier. 
% %
% $S_j = \{\seq{l}{m}{B_l \mapsto \nw_{jl}}\}$.
% %
%
% --- OR:
%
% Extending a valuation 
% %
% $\norm{\mu} = \{\seq{i}{n}{o_i \mapsto \nr_i}\}$
% %
% means to decompose each record 
% %
% $\nr_i= \{\seq{j}{k}{a_j \mapsto \nv_{ij}}\}$ 
% %
% according to a mapping 
% %
% $\nu = \{\seq{j}{k}{a_j \mapsto s_j}\}$ that carries for each attribute $a_j$ a record $s_j$, which itself consists of $l$ attributes from a generally different domain, that is, 
% %
% $s_j = \{\seq{l}{m}{c_l \mapsto w_{jl}}\}$.
% %
% In the first step we can normalize $N$ by normalizing each record $s_j$ in the same way as described earlier. 
% %
% $s_j = \{\seq{l}{m}{c_l \mapsto \nw_{jl}}\}$.
% %
%
% --- END OR

Then the refinement is achieved by multiplying \norm{M} and \norm{N}, which, for each record $\nR_i$, combines each $A$ attribute with each $B$ attribute from the corresponding record $\norm{S}_i$ to define a joined value from the two attributes. This multiplication yields the mapping 
%
$\norm{L} = \{O_1 \mapsto \nQ_1, \ldots, O_n \mapsto \nQ_n\}$
%
where each record $\nQ_i$ has the following form. 
% It has $k\times l$ entries
%
\[
\nQ_i = \{(A_1,B_1) \mapsto \norm{u}_{i11}, \ldots,
          (A_1,B_l) \mapsto \norm{u}_{i1l}, \ldots,
          (A_k,B_1) \mapsto \norm{u}_{ik1}, \ldots, 
          (A_k,B_l) \mapsto \norm{u}_{ikl}\}
\]
%
where each value $\norm{u}_{ipq}$ ($1 \leq p \leq k,1 \leq q \leq l)$
%
%, one for each element of $\{A_1,\ldots,A_k\}\times\{B_1,\ldots,B_l\}$, which are
%
is defined as follows.
\[
\norm{u}_{ipq} = \frac{\nv_{ip}\times\nw_{pq}}{100}  
\]
The implementation for \prog{extendBy} that implements this definition can be found in the accompanying code.

A comparison of the cars based on these sums implicitly values expert and personal experience equally. 
%
If we want to see how the cars compare under our personal vs.\ the expert view, we can project the valuation onto specific attributes in the \prog{Opinion} dimension, which produces either one of the two columns just shown for the printed value \prog{carOpinion}, and we can also compute the totals for those projections to see the effect of the different weightings.

\begin{haskellcode}
> total $ only Personal carOpinions
{Honda -> 50.37, BMW -> 49.63}

> total $ only Expert carOpinions 
{Honda -> 49.61, BMW -> 50.39}
\end{haskellcode}

\noindent
%
We can observe that the personal weighting slightly favors the Honda whereas the expert weighting slightly favors the BMW. We can also see that the difference between the two cars under the expert valuation is slightly larger than under the personal valuation, which is consistent with the result of \prog{total carOpinions}.

The function \prog{only} (like its dual \prog{except}) is an instance of a the following general function for extracting subsets of data.

\begin{haskellcode}
filter :: (a -> Bool) -> Info o a -> Info o a
\end{haskellcode}

\noindent
%
To facilitate the convenient projection onto individual components of tuple types, the functions' types require that the type of the attribute filtered upon (\prog{b}) is a subdimension of the attribute type of the data (\prog{a}), again see Figure \ref{fig:multi}.


Finally, we can add another dimension to our car selection problem to aggregate the different opinions about how to weight features. This happens similarly to the previous refinement step, except that the new dimension has only one attribute.

\begin{haskellcode}
weight :: a -> [(Weight,a)]
weight x = [Weighted --> x]

cars :: Val Car (Feature,Opinion,Weight)
cars = carOpinions `extendBy` info [Personal --> weight 0.6,Expert --> weight 0.4]
\end{haskellcode}

\noindent
%
By computing the total of the valuation we obtain the final verdict about how the cars' values compare according to the model.

\begin{haskellcode}
> total cars
{Honda -> 50.07, BMW -> 49.93}
\end{haskellcode}

\noindent
%
Our library contains additional functions, for example, to change individual attribute values, to add and remove attributes, or to generate ranked lists of alternatives, but the functions shown here should already give a good impression of how to work with the DSL to model hierarchical decision problems.
%
In particular, note the high degree of flexibility that the functional implementation brings to the table: We can easily change data on the fly and instantly recompute valuations, differences, ranking, etc. Moreover, we can dynamically extract different slices of the data (cf. \prog{only}) and thus explore and look at the data from different angles through queries without changing the representation.


\begin{figure}[t]
\begin{small}
    \begin{tabular}{@{}l|ccc@{}}
    \multicolumn{1}{c|}{$B_1$} 
    % \multicolumn{1}{c|}{\textit{Feature}} 
    & \bf{Price}  & \bf{MPG} & \bf{Safety} \\
    \hline  
    \bf{Honda}  & 0.51 & 0.48 & 0.48  \\ 
    \bf{BMW}    & 0.49 & 0.52 & 0.52 
    \end{tabular}
\hfill
    \begin{tabular}{@{}l|cc@{}}
    \multicolumn{1}{c|}{$B_2$} 
    % \multicolumn{1}{c|}{\textit{Opinion}} 
    & \bf{Personal}  & \bf{Experts}  \\
    \hline  
    \bf{Price}       & 0.5 & 0.2   \\ 
    \bf{MPG}    & 0.3 & 0.4   \\
    \bf{Safety}    & 0.2 & 0.4
    \end{tabular}
\hfill
    \begin{tabular}{@{}l|c@{}}
    \multicolumn{1}{c|}{$B_3$} 
    % \multicolumn{1}{c|}{\textit{Weight}} 
    & \bf{Weight}   \\
    \hline  
    \bf{Personal}  & 0.6  \\ 
    \bf{Expert}  & 0.4
    \end{tabular}
\end{small}
\caption{The AHP decision matrices for the car selection problem
%
($B_1\approx\textit{Feature}$,
$B_2\approx\textit{Opinion}$, and
$B_3\approx\textit{Weight}$).}
\label{fig:matrix}
\end{figure}


Compare this to the AHP approach in which all relevant data is stored in a set of matrices. Figure \ref{fig:matrix} shows the AHP matrix representation of our car selection example.
%
To change a decision model, these matrices have to be edited, and values have to be renormalized before new rankings can be computed.
%
Specifically, suppose we want to add a third car to be considered in the comparison. We can't simply add another row to matrix $B_1$, we also have to change all existing entries, renormalizing them based on the newly added information. Since in our approach valuations are derived from the original data through a simple function, we can regenerate the required normalized data automatically.

\begin{haskellcode}
> valuation threeCars
{Honda ->  {Price -> 31.21, MPG -> 32.26, Safety -> 34.63},
 BMW ->    {Price -> 29.48, MPG -> 35.48, Safety -> 32.16},
 Toyota -> {Price -> 39.31, MPG -> 32.26, Safety -> 33.22}}
\end{haskellcode}
%
The hierarchical composition of the different levels is expressed in AHP through a DAG that shows all the multiplicative combinations of the involved attributes as they are used to compute an overall value at the top for each of the alternatives listed at the bottom, as shown in Figure \ref{fig:dag}.
%
The graph provides a blueprint for the structure of the matrices and is typically designed at the outset of modeling a decision problem. 
%
Once we have the normalized values for the various features of the involved alternatives stored in the matrices, the matrix product $B_1 B_2 B_3$ gives the valuations of the alternatives.

\tikzstyle{startstop} = []
\tikzstyle{arrow} = []
\begin{figure}[bt]
    \centering
        \begin{tikzpicture}[node distance=1.2cm]
        level 1/.style={level distance=0.5cm}
        \node (total) [startstop] {Weight};
        \node (friends) [startstop, below of = total, xshift = -1cm] {Personal} ;
        \node (experts) [startstop, right of = friends,xshift = 1cm] {Expert}; 
        \node (price) [startstop, below of = friends,  xshift = -1cm] {Price};
        \node (fuel) [startstop, right of = price,  xshift = 1cm] {MPG}; 
        \node (safety) [startstop, right of = fuel,xshift = 1cm] {Safety};
        \node (honda) [startstop, below of = fuel,  xshift = -1cm] {Honda}; 
        \node (bmw) [startstop, right of = honda,xshift = 1cm] {BMW};
        \draw [arrow] (total.south) -- (friends);
        \draw [arrow] (total.south) -- (experts);
        \draw [arrow] (friends.south) -- (price);
        \draw [arrow] (friends.south) -- (fuel);
        \draw [arrow] (friends.south) -- (safety);
        \draw [arrow] (experts.south) -- (price);
        \draw [arrow] (experts.south) -- (fuel);
        \draw [arrow] (experts.south) -- (safety);
        \draw [arrow] (price.south) -- (honda);
        \draw [arrow] (price.south) -- (bmw);
        \draw [arrow] (fuel.south) -- (honda);
        \draw [arrow] (fuel.south) -- (bmw);
        \draw [arrow] (safety.south) -- (honda);
        \draw [arrow] (safety.south) -- (bmw);
        \end{tikzpicture}
    \caption{The AHP model for the car selection problem.}
    \label{fig:dag}
\end{figure}  


% Moreover, even for fixed valuations, our approach supports the dynamic extraction of different slices of the data (cf. \prog{only}), whereas this is not possible in the AHP representation. 
%
The AHP approach is, in its original form, a proven, effective method for solving a fixed decision problem. Our realization as an embedded DSL turns the approach into a flexible data decision exploration tool that allows users to dynamically build and adapt decision problems.


While modeling a decision problem to then compute an optimal solution is certainly the core of decision making, it is only one part of the decision-making process. Once an optimal alternative has been determined, questions often arise as to \emph{why} the chosen alternative is best, especially, why is it better than the second-best alternative? 
%
An answer that simply mentions the overall valuation score is in many cases not very satisfying, and one often wonders what it is about the first choice that makes it better than the competition.
%
We will address this question in Section \ref{sec:mds} where we show how we can \emph{explain} decisions by demonstrating how different attribute sets, working for and against a specific choice, contribute to the decision. We show how the concept of \emph{minimal dominating sets} \citep{EKF20padl} can be employed for that purpose and how it can be nicely integrated into the overall structure of our DSL.


In addition to explaining a decision, one might also wonder how relevant or decisive a decision is, that is, how much better is the first alternative than the second (or even third)? This often leads to questions of how much specific attributes have to change for the decision to change. 
%
We will address this question in Section \ref{sec:mds} 

In the following sections we will address these questions.

\NOTE{Edited up to here.}



``Why was Honda preferred over BMW?'', ``Who amongst the friends and experts was responsible for tilting the scale in favour of Honda?'', and ``Which car features led to the selection of Honda over BMW?''. 

 



\section{Explaining AHP Decisions With Minimal Dominating Sets}
\label{sec:mds}

---

is an explanation mechanism which automates the analysis of the log and can answer the questions posed above. Depending on who the user is they may want explanations at varying degree of details. For example, an expert user of the domain may want detailed explanation as compared to a non-expert who may want a more abstract explanation. Our DSL affords this flexibility to the end users and provides combinators allowing them to generate explanations at the desired degree of detail. We discuss the MDS explanation mechanism and the various explanation combinators in later on in the paper. 

---

Consider the trace of the priority synthesis step of the car example in Figure \ref{fig:PriorityLog}. The trace consists of components for both Honda and BMW. Every component corresponding to Honda or BMW consists of a component label which is a tuple of constructors corresponding to the various levels of the AHP model and a component value. 

In order to analyze the log, we might want to separate the trace components for Honda and BMW. This can be done using the \prog{select} function provided by the DSL as shown below. 
\begin{haskellcode}
type CarDecomp = Attr (Feature,User,Weight)

honda :: CarDecomp
honda = select Honda carsVal

bmw :: CarDecomp
bmw = select BMW carsVal
\end{haskellcode}

Note that same component labels are present in both Honda and BMW with different component values. Thus an element wise difference of the component values for Honda and BMW can allow us to compare their performance with regards to various decision components. This element wise difference between the trace components of two options is also known as \emph{value difference}. As a convention, we subtract the trace component for the less preferred option from that of the preferred option. In the DSL, we define the type \prog{ValDiff a}, which is a type synonym for the attribute map \prog{Attr a}, to represent the value difference. 
\begin{haskellcode}
type ValDiff a = Attr a 
\end{haskellcode}
The DSL defines a function \prog{onAttr} which takes as input a function, and two attribute maps. It applies the function recursively on the corresponding elements of the two attribute maps consquently generating an attribute map as the output. 
\begin{haskellcode}
onAttr :: Ord a => (Double -> Double -> Double) -> Attr a -> Attr a -> Attr a
onAttr g x y =  Attr $ merge preserveMissing preserveMissing
                       (zipWithMatched (\_->g)) (unAttr x) (unAttr y)
\end{haskellcode}
Using the function \prog{onAttr}, the DSL defines a function \prog{diff} which computes the value difference as shown below. 
\begin{haskellcode}
diff :: Ord a => Attr a -> Attr a -> Attr a
diff = onAttr (-)
\end{haskellcode}
Now we can compute value difference between Honda and BMW as shown below. 
\begin{haskellcode}
vdCar :: CarDecomp
vdCar = diff honda bmw

*Car> vdCar
{(Price,Friend,Weight) -> 0.009,(Price,Expert,Weight) -> 0.002,
 (Fuel,Friend,Weight) -> -0.009,(Fuel,Expert,Weight) -> -0.008,
 (Safety,Friend,Weight) -> 0.004,(Safety,Expert,Weight) -> 0.006}
\end{haskellcode}
Looking at the value difference we can deduce that value difference components with positive component values represent the components where Honda has an edge over BMW. We find that Honda leads in the price, and safety considerations both amongst friends experts. Similarly, the negative value difference components represent the components where BMW has an edge over Honda. That is, BMW leads in fuel efficiency considerations amongst friends and experts. 

The positive and negative components of the value difference are known as the \emph{support} and the \emph{barrier} for decision making. They are encoded in the DSL using the type synonyms \prog{Support a} and \prog{Barrier a} respectively, which are just type synonyms for the attribute map.
\begin{haskellcode}
type Barrier a = Attr a 
type Support a = Attr a 
\end{haskellcode}
Now we can make an observation that since Honda has a higher priority score than BMW, the sum of the support components must outweigh the sum of the barrier components (-0.009 + -0.008 = -0.017). In other words, the sum of the barrier components represent the total barrier that the support components have to overcome. 

Not all the support components may be required to overcome the total barrier. The subsets of the support that can overcome the total barrier are called the \emph{dominators}. We can have multiple dominators for a that can overcome the barrier. For the car example, we have two different dominators as shown below. The first dominator has 4 components and the second one has only 3 components. 
\begin{haskellcode}
{(Price,Friend,Weight) -> 0.009,(Price,Expert,Weight) -> 0.002,
 (Safety,Friend,Weight) -> 0.004,(Safety,Expert,Weight) -> 0.006}
 
 {(Price,Friend,Weight) -> 0.009,(Safety,Friend,Weight) -> 0.004,
 (Safety,Expert,Weight) -> 0.006}
\end{haskellcode}
These dominators act as explanations for why Honda is selected over BMW. The first explanation tell us that importance that friends and experts give to the price advantage of Honda, and the importance that both friends and experts give to the safety advantage of Honda is the reason why Honda is selected over BMW. The second explanation doesn't use the price consideration by experts. That is, the second explanation (dominator) is more concise than the first one. 

Amongst the multiple dominators that we have it makes sense for us to choose the ones with the minimum number of support components. These dominators are also called \emph{minimal dominating sets} or MDS. For the car example, the second dominator is the MDS explanation. By their very construction, we can justify that MDS explanations are the minimal explanations for why Honda was preferred over BMW. In the DSL, we define the dominators and minimal dominating sets using the types which are again the type synonyms for the attribute map. 
\begin{haskellcode}
type Dom a = Attr a 
type MDS a = Attr a 
\end{haskellcode}

The DSL defines an explanation by a type \prog{Explain b} to be a tuple of value difference, the support and the barrier components of the value difference, the list of all the dominators, and the list of all MDS explanations as shown below. 
\begin{haskellcode}
type Explain b = (ValDiff b,Support b,Barrier b,[Dom b],[MDS b])
\end{haskellcode}
The DSL also provides a function \prog{explanation} which takes as input the value difference between two options that we want to compare and generates an explanation for why one option is better than the other. It is defined as shown below. 
\begin{haskellcode}
explain :: Ord a => ValDiff a -> Explain a  
explain v = (v,mkAttr support,mkAttr barrier,map mkAttr doms,map mkAttr mdss) 
  where
    d = map (\(x,y) -> (x,y)) (fromAttr v)  
    (support,barrier) = partition (\x -> snd x>0) d 
    f = abs.sum.map snd  
    g f' = sortBy (compare `on` f')
    btotal = f barrier
    doms = g length $ [d | d <- subsequences support, f d > btotal]
    mdss = (reverse.g f) $ takeWhile (\p -> length p == (length.head) doms) doms
\end{haskellcode}
Our definition of an explanation gives us a complete view of the various components involved in the explanation process. However, with so much information reading the complete information may become difficult for the user. We provide two functions, namely \prog{pdom} and \prog{pmds}, with the below type signatures which print the explanations in readable forms: Both these functions print the value difference, the support and the barrier. However, in addition to these common components, \prog{pdom} prints all the dominators whereas \prog{pmds} prints all the MDSs. We don't show the code for these functions as these are not very interesting.
\begin{haskellcode}
pdom :: Show b => Explain b -> IO ()
pmds :: Show b => Explain b -> IO ()
\end{haskellcode}

Finally, we can generate an explanation for why Honda was selected over BMW as shown below and pretty print using \prog{pmds} function. 
\begin{haskellcode}
explCar :: Explain (Feature,User,Weight)
explCar = explain vdCar

*Car> pmds explCar

Value Difference: {(Price,Friend,Weight) -> 0.009,(Price,Expert,Weight) -> 0.002,
                  (Fuel,Friend,Weight) -> -0.009,(Fuel,Expert,Weight) -> -0.008,
                  (Safety,Friend,Weight) -> 0.004,(Safety,Expert,Weight) -> 0.006}

Support: {(Price,Friend,Weight) -> 0.009,(Price,Expert,Weight) -> 0.002,
          (Safety,Friend,Weight) -> 0.004,(Safety,Expert,Weight) -> 0.006}

Barrier: {(Fuel,Friend,Weight) -> -0.009,(Fuel,Expert,Weight) -> -0.008}

MDS: {(Price,Friend,Weight) -> 0.009,(Safety,Friend,Weight) -> 0.004,
      (Safety,Expert,Weight) -> 0.006}
\end{haskellcode}


\section{Combinators for Transforming Explanations}
\label{sec:trans}

In the last section, we generated an explanation for why Honda was preferred over BMW. Transforming explanations can make them easier to understand for an user either by presenting it in an easy to understand form or by allowing us to get answers more abstract questions. For our car example, we can answer more abstract questions like ``Which features led to the selection of Honda over BMW?'' or more fine grained questions about explanations like ``How important are friends as compared to experts in the selection of Honda over BMW?''. We also describe the combinators provided by the DSL for transforming explanations.

\subsection{Decluttering Explanations}\label{ReduceExpl}
To begin with, we notice that the attribute \prog{Weight} remains constant throughout the explanation in the MDS explanation in \prog{explCar} in the section above. Removing it would enhance the readability of explanations. We use the \prog{reduce} function provided by the \prog{Reduce} type class to remove a constant constructor value from all the component labels of a trace. The element to be removed is selected by the type annotation accompanying the reduce function. The \prog{Reduce} class definition and its two instances corresponding to the tuple of three elements are shown below. The reduce function uses a helper function \prog{rmv}, another function provided by the \prog{Reduce} type class, which removes an element from the tuple type based on type annotation. 
\begin{haskellcode}
class Reduce a b | a -> b where
  rmv :: a -> b 
  
  reduce :: (Ord a,Ord b) => Attr a -> Attr b 
  reduce = mkAttr.map (\$(x,n) -> (rmv x,n)).fromAttr

instance Reduce (a,b,c) (b,c) where
  rmv :: (a,b,c) -> (b,c)
  rmv (a,b,c) = (b,c)

instance Reduce (a,b,c) (a,c) where
  rmv :: (a,b,c) -> (a,c)
  rmv (a,b,c) = (a,c)

instance Reduce (a,b,c) (a,b) where
  rmv :: (a,b,c) -> (a,b)
  rmv (a,b,c) = (a,b)
\end{haskellcode}
In the code shown below, we extract the MDS explanations from the explanation by pattern-matching on the complete explanation \prog{expCar}, select one of extracted MDS explanations using \prog{head}, and finally remove the \prog{Weight} constructor from the selected MDS explanation using the \prog{reduce} function. This transformed MDS explanation is finally bound to \prog{mdsCar}.
\begin{haskellcode}
mdsCar :: MDS (User,Feature)
mdsCar = let (_,_,_,_,mdss) = expCar
         in  reduce (head mdss)::Attr (User,Feature)
       
*Car> mdsCar
{(Price,Friend) -> 0.009,(Safety,Friend) -> 0.004,(Safety,Expert) -> 0.006}
\end{haskellcode}

\subsection{Abstracting Explanations}
So far we have tried making explanations easier to understand for the end users. However, the explanation terms (MDS explanations) involve features from various levels which can make an explanation difficult to understand. Most human activities involve a complex interplay of various factors. It is not uncommon for us to untangle the complex interaction between the various factors and understand them one factor at a time. For example, the modern economy is a highly complex system and may depend on environmental factors like amount of rainfall, political factors like stability of the government in the country, and human/social factors like quality of labour force. It is not uncommon for economists/commentators to explain a certain economic event in terms of one factor. For example, the most popular explanation for 2008 financial crisis is the housing market collapse. 

The \emph{generalize} function provided by the type class \prog{Generalize} allows the end users to choose the level at which they seek explanation and provides the explanation at the selected level. In the context of the car example, this means that users can query ``Whose opinion prevailed in favoring Honda over BMW?''. Similarly, we can also ask ``What car features lead to the selection of Honda over BMW?''. 


Before we describe the design of the \prog{GroupBy} type class, we briefly discuss two of its superclasses, namely the \prog{Projector} and \prog{SumOut} type class. 

\prog{Projector a b} is a multi-parameter type class. The definition of the type class and its two instances for the pair type are shown below. The \prog{proj} function provided by the \prog{Projector} type class projects an element from a n-tuple based on type annotation.
\begin{haskellcode}
class Projector a b | a -> b where
  proj :: a -> b 

instance Projector (a,b) a where
  proj = fst      

instance Projector (a,b) b where
  proj = snd
 
*Car> proj (Friend,Fuel) :: Feature
Fuel
*Car> proj (Friend,Fuel) :: User
Friend
\end{haskellcode}
\prog{SumOut a b} is again a multi-parameter type class which defines the \prog{sumOut} function. The function takes an attribute map as input, which are the components of a trace. It sums out the constructors corresponding to all but one level (the level corresponding to type \prog{b}) from all the component labels of the attribute map of type \prog{Attr a}, generating an attribute map of type \prog{Attr b}.
\begin{haskellcode}
class (Projector a b,Ord b) => SumOut a b | a -> b where
  sumOut :: Attr a -> Attr b 
  sumOut = mkAttr.map h.groupBy g.sortBy (compare `on` f).fromAttr
    where h xs = ((f.head) xs,(sum.map snd) xs)
          g x y = f x == f y
          f = proj.fst
\end{haskellcode}
 For example, \prog{SumOut (a,b) b} signifies that from the combined attribute map of levels \prog{a} and \prog{b}, the attributes (constructors) corresponding to data type \prog{a} are summed out thereby generating a new attribute map entirely in terms of constructors of data type \prog{b}. \prog{SumOut a b} is a sub-class of \prog{Projector a b}. Its type class definition and the two instances for the pair type are shown below. 
\begin{haskellcode}
instance Ord b => SumOut (a,b) b 
instance Ord a => SumOut (a,b) a 
\end{haskellcode}

In the example shown below, the value difference between Honda and BMW is expressed entirely in terms of the constructors of \prog{User} by summing out the constructors of \prog{Feature} data type in the value difference.
\begin{haskellcode}
*Car> sumOut vdCar :: Attr User
{Friend -> 0.004,Expert -> 0.001}
\end{haskellcode}
Similarly, the same value difference is expressed in terms of the constructors of \prog{Feature}.
\begin{haskellcode}
*Car> sumOut vdCar :: Attr Feature
{Price -> 0.011,Fuel -> -0.016,Safety -> 0.010}
\end{haskellcode}

\prog{Generalize a b} is a multi-argument type class where type \prog{a} is the tuple of all the data types corresponding to the various levels of the AHP model and type \prog{b} represents the level at which explanation is desired. It is defined as shown below along with its two instance definitions for the pair type. 
\begin{haskellcode}
class (Ord a,Ord b,SumOut a b) => Generalize a b | a -> b where
    generalize :: ValDiff a -> Explain b
    generalize = explain.sumOut

instance (Ord a,Ord b) => Generalize (a,b) a 
instance (Ord a,Ord b) => Generalize (a,b) b 
\end{haskellcode}
\prog{Generalize a b} is a sub-class of \prog{SumOut a b}. The \prog{generalize} function uses \prog{sumOut} to covert the composite value difference of type \prog{a} to a value difference of type \prog{b} and generates explanations using this amended value difference. An interesting property to note that for the various types \prog{b}, the sum of the all the value different components remain constant. We simply redistribute the value difference in terms of the elements at that level using the \prog{sumOut} function.

For the car example, the explanation at the level of the decision makers is represented by \prog{expUser}. The explanation reveals something interesting about the choice of the decision makers which is the that both friends and experts prefer Honda over BMW. That is, both friends and experts are MDS explanations for selection of Honda over BMW. 
\begin{haskellcode}
expUser :: Explain User
expUser = generalize vdCar

*Car> pmds expUser

Value Difference:{Friend -> 0.004,Expert -> 0.001}

Support: {Friend -> 0.004,Expert -> 0.001}

Barrier: {}

MDS: {Friend -> 0.004}
     {Expert -> 0.001}
\end{haskellcode}
Similarly, the explanation at the level of features is represented by \prog{expFeat}. We see that price and safety are the features that caused Honda to be preferred over BMW.
\begin{haskellcode}
expFeat :: Explain Feature
expFeat = generalize vdCar

*Car> pmds expFeat

Value Difference: {Price -> 0.011,MPG -> -0.016,Safety -> 0.010}

Support: {Price -> 0.011,Safety -> 0.010}

Barrier: {MPG -> -0.016}

MDS: {Price -> 0.011,Safety -> 0.010}
\end{haskellcode}

\subsection{Factorizing Explanations}
There is a quantitative aspect to explanation as well. For the car example we might want to know ``How does the opinion of friends compare against that of the experts in the decision to buy Honda over BMW?'' and  ``How significant are the roles of the individual car features in the decision making process?''. We answer these fine grained questions about the MDS explanations using a transformation called \emph{factorization of explanation}. 

Factorization of an explanation extracts the contributions of the individual attributes of a given level. The DSL defines a type \prog{Factor b c} where \prog{b} is the data type corresponding the level for which we want to get the individual contributions of the various attributes and \prog{c} is the tuple of types corresponding to all but type \prog{b}. 
\begin{haskellcode}
type Factor b c = [(b,Attr c,Double)]
\end{haskellcode}

The DSL also defines a type class called \prog{GroupBy} that defines a \prog{factorize} function, which can be used to factorize explanations. The level for which the contributions of the attributes is to be computed is conveyed by type annotation. The \prog{factorize} function sums out the attributes of all but the chosen level to get the contribution of attributes of the chosen level while also tracking how the individual components from the original attribute contribute to the overall scores of the attributes.
\begin{haskellcode}
class (SumOut a b,Reduce a c,SubDim a b) => GroupBy a b c | a -> b c where
  factorize :: (Ord a,Ord b,Ord c) => Rec a -> Factor b c
  factorize xs = zipWith mkFactor (attrImpact xs) (constituents xs)
      where mkFactor     = \x y -> (fst x,y,snd x)
            attrImpact   = sort . fromRec . sumOut
            constituents = map (reduce.mkRec) . sortNgroup . fromRec
            sortNgroup   = groupBy ((==) `on` proj.fst) 
                           . sortBy (compare `on` proj.fst)

\end{haskellcode}
For example, consider the MDS explanation for \prog{mdsCar} from Section \ref{ReduceExpl}. The factorized explanation for \prog{mdsCar} in terms of the \prog{Feature} level is shown below. \prog{pFact} function pretty prints the factorizations. The factorized representation answers the question about the relative importance of the price and fuel attributes in the explanation for selecting Honda over BMW. Clearly, price seems to be a more important factor than fuel in the decision making process. We can also notice that while opinions of both the friends and experts contribute towards the price advantage for Honda over BMW, this advantage is primarily driven by the opinion of friends. In contrast all of the safety advantage of Honda is driven by the opinion of experts.
\begin{haskellcode}
mFeat = pFact (factorize mdsCar :: Factor Feature User)

*Car> mFeat
Price  : 0.011 ({Friend -> 0.009,Expert -> 0.002})
Safety : 0.006 ({Expert -> 0.006})
\end{haskellcode}
Similarly, for the \prog{User} level, it turns out that friends contribute marginally more than the experts in the selection of Honda over BMW. Moreover, all of the friends' contribution is due to their price considerations in the decision making. The contribution of experts ic comprised of both their price and safety considerations with safety being the prime contributor. 
\begin{haskellcode}
mUser = pFact (factorize mdsCar :: Factor User Feature)

*Car> mUser
Friend : 0.009 ({Price -> 0.009})
Expert : 0.008 ({Price -> 0.002,Safety -> 0.006})
\end{haskellcode}

\section{Case Study : Election Example}
We present another example here which elucidates the versatility of our DSL. This example pertains to explaining the result of presidential elections between Donald Trump and Hillary Clinton in 2016. Assume that before the elections a survey of the potential voters was conducted which tried to predict the potential outcome of the election along with the understanding the rationale for the choice of the voters. 

\tikzstyle{startstop} = []
\tikzstyle{arrow} = []
\begin{figure}[h]
    \centering
        \begin{tikzpicture}[node distance=1.2cm]
        level 1/.style={level distance=0.5cm}
        \node (total) [startstop] {Score};
        \node (rural) [startstop, below of = total, xshift = -1cm] {Rural} ;
        \node (urban) [startstop, right of = rural,xshift = 1cm] {Urban}; 
        \node (young) [startstop, below of = rural,  xshift = -1cm] {Young};
        \node (middleAged) [startstop, right of = young,  xshift = 0.7cm] {Middle Aged}; 
        \node (old) [startstop, right of = middleAged,xshift = 1.2cm] {Old};

        \node (economic) [startstop, below of = middleAged,  xshift = -1.1cm] {Economic}; 
        \node (environment) [startstop, left of = economic, xshift = -1cm] {Environment}; 
        \node (foreign) [startstop, right of = economic,xshift = 1cm] {Foreign};
        \node (health) [startstop, right of = foreign,xshift = 1cm] {Health};

        \node (clinton) [startstop, below of = economic] {Clinton}; 
        \node (trump) [startstop, right of = clinton,xshift = 1cm] {Trump};
        \draw [arrow] (total.south) -- (rural);
        \draw [arrow] (total.south) -- (urban);
        \draw [arrow] (rural.south) -- (young);
        \draw [arrow] (rural.south) -- (middleAged);
        \draw [arrow] (rural.south) -- (old);
        \draw [arrow] (urban.south) -- (young);
        \draw [arrow] (urban.south) -- (middleAged);
        \draw [arrow] (urban.south) -- (old);
        
        \draw [arrow] (young.south) -- (environment);
        \draw [arrow] (young.south) -- (economic);
        \draw [arrow] (young.south) -- (foreign);
        \draw [arrow] (young.south) -- (health);   
        
        \draw [arrow] (middleAged.south) -- (environment);
        \draw [arrow] (middleAged.south) -- (economic);
        \draw [arrow] (middleAged.south) -- (foreign);
        \draw [arrow] (middleAged.south) -- (health);   

        \draw [arrow] (old.south) -- (environment);
        \draw [arrow] (old.south) -- (economic);
        \draw [arrow] (old.south) -- (foreign);
        \draw [arrow] (old.south) -- (health);  


        \draw [arrow] (environment.south) -- (clinton);
        \draw [arrow] (economic.south) -- (clinton);
        \draw [arrow] (foreign.south) -- (clinton);
        \draw [arrow] (health.south) -- (clinton); 
        
        \draw [arrow] (environment.south) -- (trump);
        \draw [arrow] (economic.south) -- (trump);
        \draw [arrow] (foreign.south) -- (trump);
        \draw [arrow] (health.south) -- (trump); 
        \end{tikzpicture}
    \caption{AHP Model for Predicting the 2016 Presidential Election.}
    \label{AHP_Candidate}
\end{figure} 

The AHP model used for the problem is shown in Figure \ref{AHP_Candidate}. We assume that various factors affecting voters' choices are the geography of the areas they reside in that is whether they live in rural or urban areas, their age groups that is whether they are young, middle aged, or old, their policy leanings that is how to do they rate the importance of various policies like environment, economic, foreign, and health and finally the perception of the voters about how serious the two candidates are with regards to these policies. The Haskell data type representation of the various decision attributes is shown below.
\begin{haskellcode}
data Geography = Rural | Urban 
data Demography = Young | MiddleAged | Old 
data Policy = Environment | Economic | Foreign | Health 
data Candidate = Clinton | Trump 
data Population  = Population 
\end{haskellcode}
We begin by noting that 500 people are interviewed from rural and urban areas each for this opinion poll. This is encoded in Haskell in the \prog{populationInfo} distribution shown below. The object map for to the distribution is obtained using the \prog{gather} function also shown below. 
\begin{haskellcode}
populationInfo :: Population -> Spread Geography 
populationInfo Population = [Rural --> 500,Urban --> 500]

*Election> gather populationInfo
{Rural -> {Population -> 500.000},
 Urban -> {Population -> 500.000}}
\end{haskellcode}
Assume that the survey showed that the demography of rural areas is 20 \% youth, 30\% middle aged, and 50\% old. Similarly, demography of urban areas is 40\% youth, 40\% middle aged, and 20\% old. The demographic distribution of the rural and the urban areas and the corresponding object map is shown below. 
\begin{haskellcode}
geographyInfo :: Geography -> Spread Demography 
geographyInfo x = case x of
                      Rural -> [Young --> 100,MiddleAged --> 150,Old --> 250]
                      Urban -> [Young --> 200,MiddleAged --> 200,Old --> 100]
          
*Election> gather geographyInfo
{Young -> {Rural -> 100,Urban -> 200},
 MiddleAged -> {Rural -> 150,Urban -> 200},
 Old -> {Rural -> 250,Urban -> 100}}
\end{haskellcode}
The object map corresponding to \prog{geographyInfo} tells us that thereare  300 young voters in total with 100 of them in rural areas and 200 of them in urban areas. Similarly, we find that there are 350 each of middle aged and old voters in total. We can verify that this categorisation of voters also yields a total of 1000 voters, the number of voters that we started with.

Now each demography of voters expresses what policies are important to them. Assume that in young voters who are 300 in number, ${1/3}^{rd}$ (100) of them plan to vote based on a candidate's education policy, ${1/6}^{th}$ (50) each for economic and foreign policy, and the remaining ${1/3}^{rd}$ (100) for health policy. The distribution \prog{demographyInfo} shows a similar distribution for middle aged and old voters as well in addition to the young voters.
\begin{haskellcode}
demographyInfo :: Demography -> Spread Policy
demographyInfo x 
    = case x of
        Young -> [Environment --> 100,Economic --> 50,Foreign --> 50,Health --> 100]
        MiddleAged -> [Environment --> 75,Economic --> 125,Foreign --> 75,Health --> 75]
        Old -> [Environment --> 50,Economic --> 100,Foreign --> 50,Health --> 150]

*Election> gather demographyInfo
{Environment -> {Young -> 100,MiddleAged -> 75,Old -> 50},
 Economic -> {Young -> 50,MiddleAged -> 125,Old -> 100},
 Foreign -> {Young -> 50,MiddleAged -> 75,Old -> 50},
 Health -> {Young -> 100,MiddleAged -> 75,Old -> 150}}
\end{haskellcode}
We obtain the count of voters who voted for environment, economic, foreign, and health policies from the object map shown above which is 225, 275, 175, and 325 respectively. Finally, each of these four groups of voters are asked who amongst Clinton and Trump can implement the pertinent policies for their groups most effectively. For example, ${4/5}^{th}$ of the voters voting primarily on environment policies feel that Clinton is better person than Trump to legislate the policies they want implemented. The distribution for all the four policies are specified by the \prog{policyInfo} function shown below. 
\begin{haskellcode}
policyInfo :: Policy -> Spread Candidate
policyInfo x = case x of Environment-> [Clinton --> 180,Trump --> 45] 
                         Economic -> [Clinton --> 55,Trump --> 220]
                         Foreign  -> [Clinton --> 35,Trump --> 140]  
                         Health   -> [Clinton --> 195,Trump --> 130]
                         
*Election> gather policyInfo
{Clinton -> {Environment -> 180,Economic -> 55,Foreign -> 35,Health -> 195},
 Trump ->   {Environment -> 45,Economic -> 220,Foreign -> 140,Health -> 130}}
\end{haskellcode}
The object map shown above shows the breakup of voters voting for candidates based on their policy affiliations. We also find that Trump and Clinton received a total of 535 and 465 voted respectively which makes Trump the winner in the opinion polls. 

Once we have the distributions the various consecutive levels, we can compute the final valuation as shown below. The final valuation suggests that Trump has a higher chance of winning the elections than Clinton. 
\begin{haskellcode}
candidates :: Val Candidate (Policy,Demography,Geography,Population)
candidates = val' policyInfo `extend` demographyInfo `extend` geographyInfo 
             `extend` populationInfo

*Election> priority candidates
[(Clinton,0.465),(Trump,0.535)]
\end{haskellcode}

We can think of the priority scores of $0.535$ and $0.465$ for Trump and Clinton respectively as the normalized value the number of votes achieved by each of the candidate: $(535/(535 + 465) = 0.535)$ and $(465/(535 + 465) = 0.465)$. This intuition allows us a deeper understanding of the \prog{candidates} valuation shown below. We can multiply the values in the various rows in the valuation by 1000 which gives us a split of the votes in terms of the various geographies, demographics, and policies. For example, the first component of Clinton's valuation suggests that out of the 1000 voters who were polled, 27 $(0.027 \times 1000)$ rural young voters voted for Clinton's environment policies as compared to just 7 rural young voters who voted for Trumps' environmental policies. The difference is accentuated in the urban areas where Clinton's environmental policies garner a substantial 53 votes from the young population as compared to just 13 votes for Trump's policies in the same demography. 
\begin{haskellcode}
*Election> candidates
{Clinton -> {(Environment,Young,Rural,Population) -> 0.027,
             (Environment,Young,Urban,Population) -> 0.053,
                          ...
            },
 Trump -> {(Environment,Young,Rural,Population) -> 0.007,
           (Environment,Young,Urban,Population) -> 0.013,
                       ...
          }}
\end{haskellcode}

Once we have the valuation, we can separate the valuation components for Trump and Clinton and compute the valuation difference as shown below. We also remove the \prog{Population} constructor from the value difference as it remains constant through all the components of the value difference and doesn't add any useful information.
\begin{haskellcode}
type CandidateDecomp = Attr (Policy,Demography,Geography,Population)

trump :: CandidateDecomp
trump = select Trump candidates

clinton :: CandidateDecomp
clinton = select Clinton candidates

vdCandidate :: Attr (Policy,Demography,Geography)
vdCandidate = reduce $ diff trump clinton
\end{haskellcode}

\subsection{Detailed Explanations for the Election Results}
Once we compute the value difference, we can now start generating explanations. The campaign managers of the two candidates may want to know information like ``What policy of the candidates are popular and amongst which section of the electorate?" so that they can remedy the problematic areas and consolidate their areas  of strength. 

We know that the advantages for Trump (and the disadvantage for Clinton) is recorded in the support component of the explanation. Similarly, disadvantage for Trump (and advantage for Clinton) is recorded in the barrier component of the explanation. We pattern match on the explanation to extract support and barrier components as shown below.
\begin{haskellcode}
expCandidate :: Explain (Policy,Demography,Geography)
expCandidate = explain vdCandidate

(_,support,barrier,_,_) = expCandidate
\end{haskellcode}
Now to get the policies (and its breakup) where Trump is at an advantage, we could factorize the \prog{support} components with respect to policy and get the following. The factorized support component tells us that Trump's economic and foreign seem to be attracting voters. His economic policy seem to be especially popular amongst middle aged rural and urban population and old rural population. Middle aged rural and urban population seem to be strong supporters for his foreign policy as well in addition to the young urban and old rural population. 
\begin{haskellcode}
policyTrump = pFact (factorize support :: Factor Policy (Demography,Geography))

*Election> policyTrump
Economic : 0.165 ({(Young,Rural) -> 0.010,
                   (Young,Urban) -> 0.020,
                   (MiddleAged,Rural) -> 0.032,
                   (MiddleAged,Urban) -> 0.043,
                   (Old,Rural) -> 0.043,
                   (Old,Urban) -> 0.017})

Foreign : 0.105 ({(Young,Rural) -> 0.010,
                  (Young,Urban) -> 0.020,
                  (MiddleAged,Rural) -> 0.019,
                  (MiddleAged,Urban) -> 0.026,
                  (Old,Rural) -> 0.021,
                  (Old,Urban) -> 0.009})
\end{haskellcode}

We can do a similar analysis for Clinton as shown below. Note that the negative sign with the component values simply signifies the fact that these are barrier components. That is, they represent the attributes where Clinton has an advantage over Trump. We can see that Clinton's environment policies have a strong support amongst the young and middle aged urban population. She is clearly at an advantage with regards to the health policies but she manages to garner substantial support only from the old rural voters for this policy. The support from other for this policy is marginal. 
\begin{haskellcode}
policyClinton = pFact (factorize barrier :: Factor Policy (Demography,Geography))

*Election> policyClinton
Environment : -0.135 ({(Young,Rural) -> -0.020,(Young,Urban) -> -0.040,
                       (MiddleAged,Rural) -> -0.019,(MiddleAged,Urban) -> -0.026,
                       (Old,Rural) -> -0.021,(Old,Urban) -> -0.009})

Health : -0.065 ({(Young,Rural) -> -0.007,(Young,Urban) -> -0.013,
                  (MiddleAged,Rural) -> -0.006,(MiddleAged,Urban) -> -0.009,
                  (Old,Rural) -> -0.021,(Old,Urban) -> -0.009})
\end{haskellcode}

In this section we only show factorization with regards to policy and not elucidate factorizations with respect to geography or the demography. Generally, we determine the aptness of a factorization based on the tasks at hand and who the end user towards whom the explanation is aimed at. 

\subsection{Summary Explanations for Election Results}
In the last section we saw detailed explanation of election results. However, not everyone may need and want the explanation in such detail. For example, the news channels may simply want to know ``How did the geography/demography/policy impact the election of Trump over Clinton?''. That is, we want to localize the explanation provided to just one level.

We begin by explaining the impact of demography in the election. This explanation is encoded in \prog{expC1} as shown below. We observe that the young voters overall are against Trump whereas the middle aged and old voters are in his favour. The support by either of middle aged or old voters is enough to overcome the negative opinion of Trump amongst the young voters. Another thing to notice in the value difference information is the relatively strong support of Trump amongst the middle aged voters as 60 $(0.06 \times 1000 )$ more middle aged voters voted for Trump than Clinton in the opinion polls. 
\begin{haskellcode}
expDemography :: Explain Demography 
expDemography = generalize vdCandidate 

*Election> pmds expDemography

Value Difference: {Young -> -0.020,MiddleAged -> 0.060,Old -> 0.030}

Support: {MiddleAged -> 0.060,Old -> 0.030}

Barrier: {Young -> -0.020}

MDS: {MiddleAged -> 0.060}
     {Old -> 0.030}
\end{haskellcode}

To understand the impact of geographical divide on the election, We encode an explanation at the level of geography and bind it to \prog{expGeography} as shown below. It turns out that Trump wins both the rural and urban voters. There is no barrier here as no components of the value difference have negative values. This means that either of rural or urban geographies are MDS explanations for Trump's victory. This might be surprising given that initial distributions might suggest that Clinton is in stronger position in urban areas especially amongst the young voters. However, the explanation informs us that overall Trump comfortably wins the urban votes. 
\begin{haskellcode}
expGeography :: Explain Geography
expGeography = generalize vdCandidate 

*Election> pmds expGeography

Value Difference: {Rural -> 0.040,Urban -> 0.030}

Support: {Rural -> 0.040,Urban -> 0.030}

Barrier: {}

MDS: {Rural -> 0.040}
     {Urban -> 0.030}
\end{haskellcode}

Finally, to understand the impact of policies on the outcome of the election we encode the explanation at policy level and bind it to \prog{expPolicy} as shown below. The explanation at the policy level tell us that people preferred Clinton's environment and health policies to that of Trump's. However, it turns out that a strong backing of Trump's economic and foreign policy by the voters more than makes us for the negative perception he faces at the environment and health policy front. 
\begin{haskellcode}
expPolicy :: Explain Policy
expPolicy = generalize vdCandidate 

*Election> pmds expPolicy

Value Difference:
{Environment -> -0.135,Economic -> 0.165,Foreign -> 0.105,Health -> -0.065}

Support:
{Economic -> 0.165,Foreign -> 0.105}

Barrier:
{Environment -> -0.135,Health -> -0.065}

MDS:
{Economic -> 0.165,Foreign -> 0.105}
\end{haskellcode}

We have demonstrated in the section that our MDS explanation mechanism along with our DSL is flexible enough to generate explanations at varying degree of abstracting depending on the taks at hand and end users of the explanation. 

\section*{Acknowledgements}
This work is partially supported by DARPA under the grant N66001-17-2-4030 and by the National Science Foundation under the grant CCF-1717300.

% \bibliographystyle{jfplike}
% \bibliographystyle{jfp}
\bibliography{MADMReferences,References,explain,se,me}  % list here all the bibliographies that

\label{lastpage}

\end{document}
