\NeedsTeXFormat{LaTeX2e}

\documentclass{jfp}

\usepackage{amsmath}
\usepackage{amssymb}
% \usepackage{array}
% \usepackage{mathpartir}
% \usepackage[utf8]{inputenc}
% \usepackage{color, colortbl}
% \usepackage{float}

\usepackage[dvipsnames]{xcolor}
\usepackage{minted}
\usepackage{stackengine}
\usepackage{subcaption}
% \usepackage{etoolbox}
% \BeforeBeginEnvironment{minted}{\vspace{0pt plus 1pt minus 2pt}}
% \AfterEndEnvironment{minted}{\vspace{0pt plus 1pt minus 2pt}}

\usepackage{tikz}
\usetikzlibrary{positioning}
\usepackage{graphicx}
\definecolor{processblue}{cmyk}{0.96,0,0,0}
\newcommand{\NOTE}[2][gray]{\smallskip\noindent
  \colorbox{#1!30}{\parbox{.98\linewidth}{{\small\textbf{#2}}}}
}


\usepackage{natbib}
\bibliographystyle{jfp}
% \setcitestyle{authoryear, open={(},close={)}}


% \theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}


%\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand{\SP}[1][s]{\ensuremath{\textit{SP}_{#1}}}		   
\newcommand{\VD}{\textsc{vd}}		   
\newcommand{\DVD}{\textsc{dvd}}		   
\newcommand{\prog}[1]{\mintinline[fontsize=\footnotesize]{haskell}{#1}}
\newcommand{\prg}[2][blue]{\color{#1}\texttt{{\footnotesize #2}}\color{black}}


\newminted{haskell}{frame=none,framesep=2mm,xleftmargin=\parindent,samepage=true,baselinestretch=1,fontsize=\footnotesize}
\newminted[haskellfig]{haskell}{frame=bottomline,framesep=2mm,samepage=true,baselinestretch=1,fontsize=\footnotesize}

			   

% some general LaTeX settings			   
\sloppy
\sloppypar

% to typeset URLs, URIs, and DOIs
% \usepackage{url}
% \def\UrlFont{\rmfamily}
% \usepackage[hyphens]{url}
% \renewcommand{\UrlFont}{\ttfamily\small}


\begin{document}
\journaltitle{JFP}
\cpr{Cambridge University Press}
\doival{10.1017/xxxxx}

\label{firstpage}
\totalpg{\pageref{lastpage}}
\jnlDoiYr{2020}

% \title{Explanations for Dynamic Programming\thanks{This work is partially supported by DARPA under the grant N66001-17-2-4030 and by the National Science Foundation under the grant CCF-1717300.}}

\def\thetitle{A DSL for Hierarchical Explanations}

\title{\thetitle}
\righttitle{\thetitle}
\lefttitle{M.\ Erwig and P.\ Kumar}

\begin{authgrp}
\author{Martin Erwig and Prashant Kumar}
\authorrunning{M.\ Erwig and P.\ Kumar}
\affiliation{Oregon State University \\
(\email{[erwig, kumarpra]@oregonstate.edu})}
\end{authgrp}

%\received{20 March 1995; revised 30 September 1998}

\begin{abstract}
%
\end{abstract}

\maketitle

\noindent
%
% \fbox{\textbf{Conflicts of Interest: None}}

\section{Introduction}

Multi-attribute decision making (MADM) is an important component of modern decision sciences~\citep{MADMSurveys}.  It comprises a number of different techniques, one of which is is the widely used \emph{Analytic Hierarchy Process} (AHP)~\citep{SAATY1987161} which allows aspects of the decision making process to be decomposed and arranged in a hierarchy. 

The theory and methods of MADM have been extensively applied in many areas, ranging from engineering projects, economics, public administration, to management and military projects.
%
For example, in 1986 the Institute of Strategic Studies in Pretoria, a government-backed organization, used AHP to analyze the conflict in South Africa and recommended actions ranging from the release of Nelson Mandela to the removal of apartheid and the granting of full citizenship and equal rights to the black majority~\citep{articleSaatySA}. All the recommendations were implemented within a short time. Another high-profile example is the use if AHP in the 1995 US/China conflict over Chinese illegal copying of music, video, and software~\citep{SAATY2001243}. An AHP analysis involving four hierarchies for benefits, costs, opportunities, and risks showed, surprisingly, that it was much better for the US \emph{not} to sanction China. The result of the study predicted what happened. Shortly after the study was complete, the U.S.\ awarded China the most-favored nation status and didn't sanction it.
%
In the domain of business, the Xerox Corporation has used the AHP to allocate close to a billion dollars to its research projects~\citep{Saaty2002DECISIONMW}, and IBM used AHP in 1991 in designing its successful mid-range AS 400 computer~\citep{TANG199222}. IBM won the prestigious Malcolm Baldrige award for Excellence for that effort, the United State's highest presidential honor for performance excellence.

The programming language support for AHP is not commensurate with the important role it plays in decision making in today's world. Most programming languages either provide minimal or no support for AHP. Even the small number of AHP libraries offered by the various programming languages require the AHP problems to be encoded in special formats like JSON, making it even more inconvenient for end users. 
%
In this paper we address this shortcoming by introducing an embedded Haskell DSL that facilitates a convenient, high-level formulation of AHP problems. In addition to solving AHP problems our DSL can also produce explanations of why a found optimal solution is better than its alternatives.

\NOTE{Edited up to here.}


\tikzstyle{startstop} = []
\tikzstyle{arrow} = []
\begin{figure}[t]
    \centering
        \begin{tikzpicture}[node distance=1.2cm]
        level 1/.style={level distance=0.5cm}
        \node (total) [startstop] {Score};
        \node (friends) [startstop, below of = total, xshift = -1cm] {Friends} ;
        \node (experts) [startstop, right of = friends,xshift = 1cm] {Experts}; 
        \node (price) [startstop, below of = friends,  xshift = -1cm] {Price};
        \node (fuel) [startstop, right of = price,  xshift = 0.7cm] {Fuel Efficiency}; 
        \node (safety) [startstop, right of = fuel,xshift = 1.2cm] {Safety Ratings};
        \node (honda) [startstop, below of = fuel,  xshift = -1.1cm] {Honda}; 
        \node (bmw) [startstop, right of = honda,xshift = 1cm] {BMW};
        \draw [arrow] (total.south) -- (friends);
        \draw [arrow] (total.south) -- (experts);
        \draw [arrow] (friends.south) -- (price);
        \draw [arrow] (friends.south) -- (fuel);
        \draw [arrow] (friends.south) -- (safety);
        \draw [arrow] (experts.south) -- (price);
        \draw [arrow] (experts.south) -- (fuel);
        \draw [arrow] (experts.south) -- (safety);
        \draw [arrow] (price.south) -- (honda);
        \draw [arrow] (price.south) -- (bmw);
        \draw [arrow] (fuel.south) -- (honda);
        \draw [arrow] (fuel.south) -- (bmw);
        \draw [arrow] (safety.south) -- (honda);
        \draw [arrow] (safety.south) -- (bmw);
        \end{tikzpicture}
    \caption{The AHP Model for Car Selection Problem.}
    \label{AHP_Car_Selection}
\end{figure}  

\begin{figure}[t]
% \centering
\begin{subfigure}{.4\textwidth}
\begin{small}
    \begin{tabular}{l|lll}
    \multicolumn{1}{c|}{$B_3$} 
    & \bf{Price}  & \bf{Fuel} & \bf{Safety} \\
    \hline  
    \bf{Honda}  & 34000 & 30 & 9.8  \\ 
    \bf{BMW}    & 36000 & 33 & 9.1  \\ 
    \end{tabular}
\end{small}
\end{subfigure}
\begin{subfigure}{.3\textwidth}
\begin{small}
    \begin{tabular}{l|ll}
    \multicolumn{1}{c|}{$B_2$} 
    & \bf{Friends}  & \bf{Experts}  \\
    \hline  
    \bf{Price}       & 0.4 & 0.6   \\ 
    \bf{Fuel}    & 0.6 & 0.4   \\
    \bf{Safety}    & 0.6 & 0.4   \\ 
    \end{tabular}
\end{small}
\end{subfigure}
\begin{subfigure}{.2\textwidth}
\begin{small}
    \begin{tabular}{l|l}
    \multicolumn{1}{c|}{$B_1$} 
    & \bf{Weight}   \\
    \hline  
    \bf{Friends}  & 0.6  \\ 
    \bf{Experts}  & 0.4    \\
    \end{tabular}
\end{small}
\end{subfigure}

\caption{The Decision Matrices for the Car Selection Problem.}
\label{fig:AHPExampleMatrices}
\end{figure}


Imagine we want to buy a new car and are considering two choices namely Honda CRV and BMW X1. If we only consider price of the cars the decision is easy but there are other factors like the fuel efficiency and the safety ratings of the car which also need to be considered. We might know little cars and decide to rope in friends and experts for advice. The question is how do we integrate the various pieces of formation? AHP is a methodology which allows us to arrange the various decision components in a hierarchy. For our car example this looks the graph structure shown in Figure \ref{AHP_Car_Selection}. In general this hierarchical representation of the various decision components is also called the AHP model of the decision problem. 

We start encoding the example in our DSL by defining the Haskell data types for various levels. 
\begin{haskellcode}
data Weight  = Weight
data User    = Friend | Expert 
data Feature = Price | Fuel | Safety 
data Car     = Honda | BMW  
\end{haskellcode}

How do we make use of the AHP model that we have for the problem? We begin by listing the values of the various car features side by side for Honda and BMW shown by matrix $B_3$ in Figure \ref{fig:AHPExampleMatrices}. Now we note the importance that friends and experts give to each of the car features in matrix $B_2$. Finally, we express the importance that we assign to the advice of friends and experts in matrix $B_1$. These matrices are also called \emph{decision matrices} in the AHP parlance. 

The DSL defines the attribute map \prog{Attr a} and the \prog{Obj o a} to encode the decision matrices described above. 
\begin{haskellcode}
data Attr a = Attr {unAttr :: M.Map a Double}
data Obj o a = Obj {unObj :: M.Map o (Attr a)}
\end{haskellcode}
An attribute map lists the value of the various attributes listed at a given level of the AHP model. We use an object map \prog{Obj o a} to encode the various decision matrices of an AHP. The user, however, doesn't need to worry about constructing or modifying the object map themselves. We provide combinators which make it convenient to work with these definitions. 

The DSL defines a \prog{Spread} type to associate the distribution of values for different objects for a given attribute.
\begin{haskellcode}
type Spread o = [(o,Double)]
\end{haskellcode}
Now we record the basic data about the car using the \prog{featureInfo} function shown below which can be converted into object maps using the \prog{gather} function. 
\begin{haskellcode}
featureInfo :: Feature -> Spread Car
featureInfo x 
    = case x of Price ->  [Honda --> 34000,BMW --> 36000]
                Safety -> [Honda --> 9.8,BMW --> 9.1]
                Fuel   -> [Honda --> 30,BMW --> 33]

features :: Obj Car Feature
features = gather featureInfo

*Car> features
{Honda -> {Price -> 34000,Fuel -> 30,Safety -> 9.8},
 BMW   -> {Price -> 36000,Fuel -> 33,Safety -> 9.1}}
\end{haskellcode}
We similarly create two more object maps: \prog{users} between the level of decision makers (friends and experts) and that of the car features and a map \prog{weight} showing the importance attached to the recommendations of the various decision makers as shown below. 
\begin{haskellcode}
userInfo :: User -> Spread Feature
userInfo x = case x of Friend -> [Price --> 0.5, Fuel --> 0.3, Safety --> 0.2]
                       Expert -> [Price --> 0.2, Fuel --> 0.4, Safety --> 0.4]

users :: Obj Feature User
users = gather userInfo

weightsInfo :: Weight -> Spread User 
weightsInfo Weight = [Friend --> 0.6,Expert --> 0.4]

weights :: Obj User Weight
weights = gather weightsInfo
\end{haskellcode}

The different car features are expressed in different units which makes any sort of comparison between them difficult. This is because for some features like fuel efficiency (measured in miles/gallon) a higher numerical value is desirable whereas for some other features like price a low numerical value is desirable. The normalization step solves this problem by converting the values of various features expressed in their respective units to unit-less relative values between 0 and 1. 

The DSL defines a type class \prog{AttrValence} which implements the \prog{valence} function. The \prog{valence} function specifies the valency of various attributes at a given level as demonstrated by the \prog{AttrValence} instance declaration of the \prog{Feature} data type shown below. 
\begin{haskellcode}
data Valence = Pos | Neg

class Ord a => AttrValence a where
   valence :: a -> Valence
   valence _ = Pos

instance AttrValence Feature where
   valence Price  = Neg
   valence Fuel   = Pos
   valence Safety = Pos
\end{haskellcode}

The \prog{valuation} function provided by the DSL allows us to normalize the various feature values in an object map. The DSL defines a type \prog{Val o a}, which is a type synonym for \prog{Obj o a}, to represent normalized object mappings. The normalized \prog{features} object map is shown below. Note that for every normalized feature say price, the feature values for the two options Honda (0.514) and BMW (0.486) sum to 1.  
\begin{haskellcode}
*Car> valuation features
{Honda -> {Price -> 0.514,Fuel -> 0.476,Safety -> 0.519},
 BMW   -> {Price -> 0.486,Fuel -> 0.524,Safety -> 0.481}}
\end{haskellcode}
Note that in the example below, we use the \prog{val} functions to perform two operations on the object value features: it performs a valuation of the object mapping and post that makes the attribute one element tuple.
\begin{haskellcode}
val :: (Set o,AttrValence a) => Obj o a -> Val o (OneTuple a)
val = mkOneTuple . valuation
\end{haskellcode}

Once we have the normalized values of the various features of the car, we are now ready to find out which car we should buy. In AHP methodology the various normalized decision matrices are multiplied to arrive at the priority scores for the various car options. More specifically, the matrix product ${B_3}^{'} B_2 B_1$, where ${B_3}^{'}$ is the normalized matrix corresponding to $B_3$ (Figure \ref{fig:AHPExampleMatrices}), gives us the priority scores of Honda and BMW. Note that matrix $B_2$ and $B_1$ are already normalized and thus need not be modified. The priorities for the options show their ``goodness'' or their desirability from a decision making point of view. 

The DSL defines a type class \prog{ExtendVal} (that stands for ``extend valuations'') which defines a function called \prog{extendBy}. We can synthesize the priorities for the car options from the corresponding object maps using the \prog{extendBy} function. The priority synthesis computation for our car example is shown below. 
\begin{haskellcode}
cars :: Val Car (Feature,User,Weight)
cars = val features `extendBy` users `extendBy` weights
\end{haskellcode}

Once we have performed the priority synthesis step, we can find out the individual priorities of Honda and BMW as shown below. As we can see Honda edges out BMW to become the preferred car. 
\begin{haskellcode}
*Car> priority cars
[(Honda,0.503),(BMW,0.497)]
\end{haskellcode}

Now that we have the priority values of the cars, we may want to understand the decision making process like what role did the various decision components and the different decision makers play in the outcome. The DSL provides a log of the priority synthesis step which can help us answer questions like the above. The priority synthesis log for the car example is shown below. 
\begin{figure}
    \centering
\begin{haskellcode}
*Car> cars
{Honda -> {(Price,Friend,Weight) -> 0.154,
           (Price,Expert,Weight) -> 0.041,
           (Fuel,Friend,Weight) -> 0.086,
           (Fuel,Expert,Weight) -> 0.076,
           (Safety,Friend,Weight) -> 0.062,
           (Safety,Expert,Weight) -> 0.083},
 BMW   -> {(Price,Friend,Weight) -> 0.146,
           (Price,Expert,Weight) -> 0.039,
           (Fuel,Friend,Weight) -> 0.094,
           (Fuel,Expert,Weight) -> 0.084,
           (Safety,Friend,Weight) -> 0.058,
           (Safety,Expert,Weight) -> 0.077}}
\end{haskellcode}
    \caption{The Priority Synthesis Log for the Car Example}
    \label{fig:my_label}
\end{figure}

The log tells us that the since the price of Honda is lower than that BMW, and since the friends factor the price very heavily in recommending a new car, their combined effect contributes a large value of 0.154 out of the total priority score 0.503 of Honda. In contrast, the combined effect of friends and their price consideration contributes 0.146 out of the total priority score 0.497 of BMW. We can do this for all the decision components and gain a deeper understanding of why Honda gets a higher priority score than BMW.

The analysis of the priority synthesis log is a good starting point to understand the output of AHP, however, manually analyzing the logs may become tedious or may not even be possible when the size of the log gets large. Additionally, this ad hoc analysis may not be able to answer the more abstract questions posed by the users like ``Why was Honda preferred over BMW?'', ``Who amongst the friends and experts was responsible for tilting the scale in favour of Honda?'', and ``Which car features led to the selection of Honda over BMW?''. 

\emph{Minimal Dominating Sets}~(MDS)~\citep{DBLP:conf/padl/ErwigKF20} is an explanation mechanism which automates the analysis of the log and can answer the questions posed above. Depending on who the user is they may want explanations at varying degree of details. For example, an expert user of the domain may want detailed explanation as compared to a non-expert who may want a more abstract explanation. Our DSL affords this flexibility to the end users and provides combinators allowing them to generate explanations at the desired degree of detail. We discuss the MDS explanation mechanism and the various explanation combinators in later on in the paper. 

We may want to add one other car namely Toyota 4Runner to the list of cars to choose from. This requires us to amend the decision matrix to reflect the updated price. Let us for a moment look at how this task would be handled by other existing libraries for AHP. Most of the these library take normalized decision matrices as input. Thus, we may only have access to the normalized decision matrix while trying to amend it. To amend the decision matrix, we need to revert to the original unnormalized matrix, amend the unnormalized matrix with the values for Toyota and normalize the amended matrix again. There can be a situation where the person who collected the unnormalized matrix values in original units is not available and all we are left with is the normalized decision matrix. This makes the task of amending and maintaining AHP code difficult. 

Our DSL allows us to work with unnormalized values. It also provides combinators to assist in modifying the AHP model and the associated decision matrices which we elucidate below. We begin by amending the \prog{Car} data type to add the Toyota constructor and create a function \prog{toyotaAttributes} specifying the value of the various attributes for Toyota. 
\begin{haskellcode}
data Car = Honda | BMW | Toyota 

toyotaAttributes :: Feature -> Double
toyotaAttributes x = case x of
        Price  -> 20000
        Safety -> 50
        Fuel   -> 30
\end{haskellcode}
We finally use the \prog{addAlternative} function to add the Toyota alternative with its different attribute values stored in \prog{toyotaAttributes} to the existing object map \prog{features} which consists of Honda and BMW as shown below. 
\begin{haskellcode}
features' :: Obj Car Feature
features' = addAlternative Toyota toyotaAttributes features
 \end{haskellcode}

Suppose we want to upgrade to a different Honda CRV variant which has a higher price of 35000 but has the same fuel efficiency and safety rating and may want to update the price of Honda. The DSL defines a function \prog{modAttribute} which updates an attribute of an existing object map as shown below. 
\begin{haskellcode}
featuresM = modAttribute features Price Honda 35000
*Car> featuresM
{Honda  -> {Price -> 35000,Fuel -> 30,Safety -> 9.8},
 BMW    -> {Price -> 36000,Fuel -> 33,Safety -> 9.1}}
\end{haskellcode}

Assume that we realize that we don't plan to use the car on a day to day basis which means that fuel efficiency is no longer of concern to us. The DSL provides a \prog{delAttribute} function which can be used to delete the now extraneous fuel feature from the object map as shown below. 
\begin{haskellcode}
featuresD = delAttribute features Fuel
*Car> featuresD
{Honda ->  {Price -> 34000,Safety -> 9.8},
 BMW   ->  {Price -> 36000,Safety -> 9.1}}
\end{haskellcode}


% Note that our DSL allows the users to encode the decision matrices without normalizing them which has implications for modification, and maintainability of the AHP code. Consider the normalized decision matrix between the alternative level and the feature level of the car example shown in the Figure \ref{fig:normalized}. Suppose that we want to amend this matrix with the values of a third alternative Toyota. To do so, we need to revert to the original unnormalized matrix, amend the original matrix with the values for Toyota and normalize the amended matrix again. There can be a situation where the person who collected the unnormalized matrix values in original units is not available and all we are left with is the normalized decision matrix. 

% Scenarios like this make the task of modifying and maintaining the AHP code difficult. However, this is not a problem for our DSL where users can work with unnormalized values. It also provides combinators to assist in modifying the AHP model and the associated decision matrices which we elucidate below. 


% Our DSL automates the analysis of the log described above using an explanation mechanism called \emph{Minimal Dominating Sets}~(MDS)~\citep{DBLP:conf/padl/ErwigKF20}. Using this explanation mechanism we can get explanations for comparative questions like ``Why is Honda a better option


% provides the facility to answer comparative question of the form shown above using an explanation mechanism called \emph{Minimal Dominating Sets}~(MDS)~\citep{DBLP:conf/padl/ErwigKF20}. Moreover, depending on who the user is they may want explanations at varying degree of details. For example, an expert user of the domain may want detailed explanation as compared to a non-expert who may want a more abstract explanation. Our DSL affords this flexibility to the end users and provides combinators allowing them to generate explanations at the desired degree of detail. 

% Additionally, given the magnitude of the policy and monetary implications of the decision problems analyzed with AHP, it is imperative that the decision makers get an explanation for the decisions suggested by AHP. In that regard, a popular tool that the researchers currently employ is a statistical technique called \emph{sensitivity analysis} \citep{triantaphyllou_2000} which analyzes how the change in the value of an input component impact the output generated by AHP. 

% However, sensitivity analysis is not an ideal explanation mechanism for AHP. Decision makers are mostly interested in seeking answers to the questions of the form ``Why was option $X$ recommended as a better alternative than option $Y$ by the AHP method?'' which the sensitivity analysis is not equipped to provide. Getting satisfactory answers to their questions may become the difference between accepting and rejecting the recommendations of the AHP especially when the two options seem equally good, that is their priority scores computed by AHP are close. 

% Our DSL provides the facility to answer comparative question of the form shown above using an explanation mechanism called \emph{Minimal Dominating Sets}~(MDS)~\citep{DBLP:conf/padl/ErwigKF20}. Moreover, depending on who the user is they may want explanations at varying degree of details. For example, an expert user of the domain may want detailed explanation as compared to a non-expert who may want a more abstract explanation. Our DSL affords this flexibility to the end users and provides combinators allowing them to generate explanations at the desired degree of detail. 


% The relationship between any 2 consecutive levels of an AHP model is recorded using a \emph{decision matrix}, an example of which is shown in Figure \ref{fig:AHPExampleMatrices}: Figure \ref{fig:unnormalized} shows the values of the various columns of the decision matrix expressed in their original units, also called the unnormalized form of the decision matrix and Figure \ref{fig:normalized} shows the normalized form of the decision matrix wherein every entry in the matrix is represented by a number between 0 and 1. 

%  To begin encoding the example, we start by representing the decision components at the various levels of AHP with Haskell data types as shown below.




% Our DSL allows the programmers to incrementally build the various decision matrices which we describe below. This is unlike other libraries which take a one shot approach at creating decision matrices, an inconvenience for the users.

% We begin encoding the example by starting with an empty object map \prog{objects}, that is a map with empty attribute maps associated with the every object. \prog{objects} associates the various objects like Honda, BMW in this case with empty attribute maps generated by the \prog{noAttributes} function. \prog{mkAttr} and \prog{mkObj} are functions provided by the DSL which convert a list of pairs of the appropriate types to attribute and object values respectively. \prog{Set} is a type class that defines the \prog{members} function which lists all the constructors of a enumerable data type. 
% \begin{haskellcode}
% noAttributes :: Ord a => Attr a
% noAttributes = mkAttr []

% objects :: (Set o,Ord a) => Obj o a
% objects = mkObj [(o,noAttributes) | o <- members]
% \end{haskellcode}
% We use the \prog{Spread} type to associate the distribution of values for different objects for a given attribute.
% \begin{haskellcode}
% type Spread o = [(o,Double)]
% \end{haskellcode}

% We can now add the price for each car by extending the empty object map by adding the price attribute to the attribute map of each car using the \prog{addAttribute} function defined below. The \prog{addAttribute} function takes as input the attribute to be added, the spread value of various objects for the given attribute, and the object map to be amended. It modifies the object map by adding the new attribute and the attribute value to the attribute map associated with every object of the object map.
% \begin{haskellcode}
% addAttribute :: (Ord o,Ord a) => a -> Spread o -> Obj o a -> Obj o a
% addAttribute c as bs = mkObj [(b,f c av bv) | (a,av) <- as,
%                               (b,bv) <- fromObj bs,a == b]
%     where f x xv ys = Attr $ M.insert x xv (unAttr ys)
% \end{haskellcode}


% We get the object map \prog{featureP} by adding the prices of cars to the empty object map. 
% \begin{haskellcode}
% featuresP :: Obj Car Feature
% featuresP = addAttribute Price [Honda --> 36000,BMW --> 24000] objects

% *Car> featuresF
% {Honda -> {Price -> 36000},
%  BMW   -> {Price -> 24000}}
%  \end{haskellcode}
%  We can sequentially extend \prog{featureP} with safety ratings and fuel efficiency measurements for the cars which gives us the final map as shown below.
% \begin{haskellcode}
% featuresS :: Obj Car Feature
% featuresS = addAttribute Safety [Honda --> 30,BMW --> 70] featuresP

% featuresF :: Obj Car Feature
% featuresF = addAttribute Fuel [Honda --> 36,BMW --> 24] featuresS

% *Car> featuresF
% {Honda -> {Price -> 36000,Fuel -> 36,Safety -> 30},
%  BMW   -> {Price -> 24000,Fuel -> 24,Safety -> 70}}
% \end{haskellcode}

% If the incrementally gathering becomes tedious, we also have a way of creating the object map in go using the \prog{gather} function defined below. The function takes as input a map of the \prog{Spread} values for the various attributes of a given level, and recursively adds these attributes to the empty object map. The final object map has all the attributes added to it. 
% \begin{haskellcode}
% gather :: (Set o,Set a) => (a -> Spread o) -> Obj o a
% gather f = foldl (\o a -> addAttribute a (f a) o) objects members
% \end{haskellcode}
% To add all the attributes in one go in our example, we create a \prog{featureInfo} function which is specifies the values of the various features for Honda and BMW. The \prog{featureInfo} function is supplied as an argument to the \prog{gather} function. \prog{feature} and \prog{featureF} are the same object maps constructed in different ways.
% \begin{haskellcode}
% featureInfo :: Feature -> Spread Car
% featureInfo x 
%     = case x of Price -> [Honda --> 24000,BMW --> 36000]
%                 Safety -> [Honda --> 30,BMW --> 70]
%                 Fuel   -> [Honda --> 36,BMW --> 24]

% features :: Obj Car Feature
% features = gather featureInfo
% \end{haskellcode}

% Note that our DSL allows the users to encode the decision matrices without normalizing them which has implications for modification, and maintainability of the AHP code. Consider the normalized decision matrix between the alternative level and the feature level of the car example shown in the Figure \ref{fig:normalized}. Suppose that we want to amend this matrix with the values of a third alternative Toyota. To do so, we need to revert to the original unnormalized matrix, amend the original matrix with the values for Toyota and normalize the amended matrix again. There can be a situation where the person who collected the unnormalized matrix values in original units is not available and all we are left with is the normalized decision matrix. 

% Scenarios like this make the task of modifying and maintaining the AHP code difficult. However, this is not a problem for our DSL where users can work with unnormalized values. It also provides combinators to assist in modifying the AHP model and the associated decision matrices which we elucidate below. 

% We can add Toyota to object map using the \prog{addAlternative} function. It takes as input the object to be appended to the object map, a map showing the values of the various attributes for the given object, and the object to be amended. The amended object map consists of the new object with its different attributes and attribute values.
% \begin{haskellcode}
% addAlternative :: (Ord o,Ord a) => o -> (a -> Double) -> Obj o a -> Obj o a
% addAlternative o f vs = Obj $ M.insert o (mkAttr ls) (unObj vs)
%     where ls = map (\x -> (x,f x)) members
% \end{haskellcode}

% We begin by amending the car data type to add the Toyota constructor and create a function \prog{toyotaAttributes} specifying the value of the various attributes for Toyota. 
% \begin{haskellcode}
% data Car = Honda | BMW | Toyota 

% toyotaAttributes :: Feature -> Double
% toyotaAttributes x = case x of
%         Price  -> 20000
%         Safety -> 50
%         Fuel   -> 30
% \end{haskellcode}
% We finally use the \prog{addAlternative} function to add the Toyota alternative with its different attribute values stored in \prog{toyotaAttributes} to the existing object map \prog{features} which consists of Honda and BMW as shown below. 
% \begin{haskellcode}
% features2 :: Obj Car Feature
% features2 = addAlternative Toyota toyotaAttributes features

% *Car> features2
% {Honda  -> {Price -> 24000,Fuel -> 36,Safety -> 30},
%  BMW    -> {Price -> 36000,Fuel -> 24,Safety -> 70},
%  Toyota -> {Price -> 20000,Fuel -> 30,Safety -> 50}}
%  \end{haskellcode}
 
% We can also delete an attribute from an already existing object map using the \prog{delAttribute} function. The function goes through every object of the object map sequentially and removes the specified attribute from the attribute map associated with each object.
% \begin{haskellcode}
% delAttribute :: (Ord o,Ord a) => Obj o a -> a -> Obj o a
% delAttribute os a = mkObj [(o,f a ov) | (o,ov) <- fromObj os]
%         where f x xs = Attr $ M.delete x (unAttr xs)
% \end{haskellcode}
% For example, if we want to get rid of the fuel efficiency attribute from the feature level in our car example, it could be done as follows.
% \begin{haskellcode}
% featuresD = delAttribute features Price
% *Car> featuresD
% {Honda ->  {Fuel -> 36,Safety -> 30},
%  BMW   ->  {Fuel -> 24,Safety -> 70}}
% \end{haskellcode}

% We can also modify the value of an attribute for an object in an existing object map with the \prog{modAttribute} function as shown below.
% \begin{haskellcode}
% modAttribute :: (Ord a,Ord o) => Obj o a -> a -> o -> Double ->  Obj o a
% modAttribute os a o' v 
%     = mkObj [if o == o' then f a o v  ov else p | p@(o,ov) <- fromObj os]
%     where f a o v ov = (o,Attr $ M.insert a v (M.delete a (unAttr ov)))
% \end{haskellcode}
% Assume that we become interested in slightly higher end model of Honda CRV which cost 30000 dollars instead of 240000, then we can amend the object map to reflect this change using the \prog{modAttribute} function as shown below.
% \begin{haskellcode}
% featuresM = modAttribute features Price Honda 45000
% *Car> featuresM
% {Honda  -> {Price -> 30000,Fuel -> 36,Safety -> 30},
%  BMW    -> {Price -> 36000,Fuel -> 24,Safety -> 70}}
% \end{haskellcode}



The rest of the paper is structured as follows. In Section \ref{} we describe the MDS explanation mechanism along with the various combinators for explanations provided by the DSL. Finally, we finish with a substantial real world AHP example which shows the explanation capabilities afforded by our DSL described in Section \ref{}. 


% \subsection{Introduction to MADM and Hierarchical Decision Making}\label{MADMIntro}


% The various options available for selection to the decision maker are called \emph{alternatives}. The MADM process produces a ranking of the various alternatives based on various factors called \emph{attributes}. For example, assume that we want to buy a new car and have the option of buying either a Honda, BMW, or a Toyota which are the alternatives of the decision problem. Our criteria for selecting the car is based on the price of the car, the fuel efficiency of the car, and the safety rating of the car, the attributes of our decision problem. 

% We assign each attribute a \emph{weight}, a fractional value signifying how important a certain attribute is to the overall decision making process. All the weights must sum to 1. For example, consider a price sensitive customer for whom safety is not a major concern. A possible weight distribution of the three attributes could be $0.6$, $0.3$, and $0.1$ respectively. Similarly, a cab company for which price as well as the fuel efficiency might be equally important may assign a weight distribution of $0.4$, $0.4$, and $0.2$ respectively. A matrix showing the value of the attributes for the various alternatives is called a \emph{decision matrix}.

% MADM does not refer to just one method but rather to a family technique. We classify the MADM techniques based on how the attributes are arranged. In linear MADM techniques like the \emph{Weighted Sum Model (WSM)}, the attributes are arranged linearly like in the car selection example described above. A hierarchical MADM technique called the \emph{Analytic Hierarchy Process (AHP)} arranges the attributes in a hierarchical manner. In our car example, we could seek the advice of friends and experts to select the appropriate car each of who use price, fuel efficiency, and safety rating to evaluate the aptness of the cars. We then assign weights to the the recommendations of friends and experts. The AHP model for selecting the car is shown in Figure \ref{AHP_Car_Selection}. 

% The specification of an AHP problem includes a set of decision matrices in addition to the AHP model of the problem. One decision matrix is required for every pair of consecutive levels in the AHP model. The alternatives in an AHP are placed at the bottom of the AHP model. In our example where the car brands Honda, and BMW are placed at the bottom of the AHP model. 

% The AHP model for the car example has 3 pairs of consecutive levels and consequently three decision matrices. For example, one of these three decision matrices is between the level of alternatives, and the level of car features (like price, and fuel efficiency) and is shown in Figure \ref{fig:AHPExampleMatrices}: The car alternatives act as row labels of the matrix and the car features acts the column labels. 

% The various columns of the decision matrices are specified in different units which makes any comparison between these columns difficult. Before proceeding any further in decision making, we normalize the various columns of the decision matrices. \emph{Normlization} aims to reduce all the values in the various column between 0 and 1. We discuss the normalization process in detail in Section \ref{}. 

% Once all the decision matrices are normalized, we finally multiply the various decision matrices to get the final priorities of the alternatives. This is called the \emph{priority synthesis} step in AHP. This steps yield a priority score, which is a number between 0 and 1, for every alternative. The priority score of an alternative signifies its desirability in the current decision problem. That is, higher the priority score of an alternative the more desirable it is and vice versa. The sum of all the alterantives in the decision problem must sum to 1. 




% \subsection{Introduction to MDS Explanations}
% \NOTE{This section consists of introduction to linear MDS explanation to begin with. Post that we need a section on hierarchical MDS explanations.}

% \subsection{The Current State of Tools for AHP and Our Contributions}
% We looked at the software tools available for encoding AHP problems. These software tools can be divided into two categories based on their interface: programming language support in the form of libraries and web based tools. For example, \emph{ahp} is a library provided in R that allows programmers to encode AHP problems. While the library allows programmers ample flexibility to specify the AHP model, the interface is cumbersome. For instance, the structure of the AHP problem is encoded in a separate file which is then included in the R file. This complexity of interface means that only programmers and not the end users can use the library. The web based tools like \emph{Expert Choice} lie on the other end of the spectrum where the web based interface makes the specification of the AHP model easy. However, this ease of specification comes at the cost of flexibility and the end user are stuck with the functionalities that the tool makers deem necessary. 

% Our DSL tries to remedy these problems by providing an intuitive interface to specify the AHP model. For instance, rather than having to provide normalized decision matrices to encode the relationship between consecutive levels, a common representation in most libraries used to encode AHP, we provide the end users with the ability to encode these relationships in the units they deem natural to express an attribute in. For example, it is easier for the end users to understand and specify the real prices of Honda and BMW which are 24,000 and 36,000 dollars respectively than to assign the normalized values of 0.4 and 0.6 respectively. 

% The end users might need to modify the AHP model several times during the process of decision making. For example, they might want to add Toyota in addition to the Honda and BMW as an alternative in the car example. Additionally, they might want to modify the value of an attribute or remove an attribute altogether. These operations pose challenges for both the categories of tools specified which results in end users having to manually adjust the model themselves which may be burden some. 

% Consider the normalized decision matrix between the alternative levels, and the car level shown in the Figure \ref{}. Suppose that we want to amend the normalized decision matrix shown in Figure with the values of the third alternative Toyota. To do so, we need to revert to the original unnormalized matrix, amend the original matrix with the values for Toyota and normalize the amended matrix again. There can be a situation where the person who collected the unnormalized matrix values in original units is not available and all we are left with is the normalized decision matrix. Situations like this make the task of modifying and maintaining the AHP code difficult. Our DSL remedies this by allowing the end users a more abstract interface for modification which automates all the manual steps listed in the modification process thereby making the code written using our DSL easy to modify and maintain. 

% Another drawback of most of the other tools is that their primarily focus is to obtain a ranking of the alternatives. While admittedly obtaining the ranking is the primary focus of AHP, given the scale and importance of decision problems analyzed with AHP the confidence of the end users in the generated decisions is equally important. The other tools listed above make an effort in this regard by providing support for better visualization of the generated outcome, and in some cases providing the option of performing \emph{sensitivity analysis} on the various attributes of the AHP model. However, we  believe that the primary way to boost the end user confidence in the outcome is to enable them to understand the rationale for the decision generated by the AHP process. Our DSL records the intermediate steps that occur in the priority synthesis phase of AHP and uses this information to provide MDS explanations for the rankings produced by the AHP mechanism. 

% We believe that one of our important contributions pertains to repuprosing the AHP mechanism. The theory that we describe in the paper makes AHP a explanation tool which can provide explanations at varying degrees of details in addition to just being a decision making tool. We substantiate our hypothesis through the election example in Section \ref{} where we already know the outcome of the polls but we still use AHP to better understand the rationale of the outcome. 

\section{Explaining AHP Decisions With Minimal Dominating Sets}


\section{Introduction to the DSL}
% We introduce the various aspects of our DSL using the car example described in Section \ref{MADMIntro}. To begin with, we can represent the various levels of the decision process in AHP with Haskell data types as shown below.
% \begin{haskellcode}
% data Weight  = Weight 
% data User    = Friend | Expert 
% data Feature = Price | Fuel | Safety 
% data Car     = Honda | BMW  
% \end{haskellcode}

% \subsection{Creating Object Values}
% Now we can relate the consecutive levels of the AHP which can happen in steps. We define an attribute map \prog{Attr a} and an object map \prog{Obj o a}as shown below. An attribute map lists the value of the various attributes listed at a given level of the AHP. We use an object map \prog{Obj o a} to associate an attribute \prog{a} like price or fuel efficiency with an object \prog{o} like Honda or BMW. 
% \begin{haskellcode}
% data Attr a = Attr {unAttr :: M.Map a Double}
% data Obj o a = Obj {unObj :: M.Map o (Attr a)}
% \end{haskellcode}
% For example, the attribute map and the object map for the \prog{Feature} level corresponding to BMW are shown below. 
% \begin{haskellcode}
% -- Attribute map
% {Price -> 36000,Fuel -> 24,Safety -> 70} 
%  -- Object map
% {BMW -> {Price -> 36000,Fuel -> 24,Safety -> 70}}
% \end{haskellcode}

% To begin encoding the example, we can assign each car its price using the object and attributes maps that we defined. We start with an empty object map \prog{objects}, an object map which has empty attribute maps associated with every object. \prog{objects} associates the various objects like Honda, BMW in this case with empty attribute maps generated by the \prog{noAttributes} function. We extend the empty object map by adding the price attribute to the attribute map of each car using the \prog{addAttribute} function. We use the \prog{Spread} type to associate the distribution of values for different objects for a given attribute. 
% \begin{haskellcode}
% type Spread o = [(o,Double)]

% noAttributes :: Ord a => Attr a
% noAttributes = mkAttr []

% objects :: (Set o,Ord a) => Obj o a
% objects = mkObj [(o,noAttributes) | o <- members]
% \end{haskellcode}

% The \prog{addAttribute} function takes as input the attribute to be added, the spread value of various objects for the given attribute, and the object map to be amended. It modifies the object map by adding the new attribute and the attribute value to the attribute map associated with every object of the object map.
% \begin{haskellcode}
% addAttribute :: (Ord o,Ord a) => a -> Spread o -> Obj o a -> Obj o a
% addAttribute c as bs 
%     = mkObj [(b,f c av bv) | (a,av) <- as,(b,bv) <- fromObj bs,a == b]
%     where f x xv ys = Attr $ M.insert x xv (unAttr ys)
% \end{haskellcode}
% We get the object map \prog{featureP} by adding the prices of cars to the empty object map. Similarly, we can sequentially extend \prog{featureP} with safety and fuel efficiency measurements for the cars which gives us the final map.
% \begin{haskellcode}
% featuresP :: Obj Car Feature
% featuresP = addAttribute Price [Honda --> 36000,BMW --> 24000] objects

% *Car> featuresF
% {Honda -> {Price -> 36000},
%  BMW -> {Price -> 24000}}

% featuresS :: Obj Car Feature
% featuresS = addAttribute Safety [Honda --> 30,BMW --> 70] featuresP

% featuresF :: Obj Car Feature
% featuresF = addAttribute Fuel [Honda --> 36,BMW --> 24] featuresS

% *Car> featuresF
% {Honda -> {Price -> 36000,Fuel -> 36,Safety -> 30},
%  BMW -> {Price -> 24000,Fuel -> 24,Safety -> 70}}
% \end{haskellcode}
% If the number of attributes at the two levels being connected by the object map \prog{Obj o a}, that is levels corresponding to types \prog{o} and \prog{a}, is large then we can compute the final object map in one go using the \prog{gather} function as shown below. The function takes as input a map of the \prog{Spread} values for the various attributes of a given level, and recursively adds these attributes to the empty object map. The final object map has all the attributes added to it. 
% \begin{haskellcode}
% gather :: (Set o,Set a) => (a -> Spread o) -> Obj o a
% gather f = foldl (\o a -> addAttribute a (f a) o) objects members
% \end{haskellcode}
% To add all the attributes in one go in our example, we create a \prog{featureInfo} function which is specifies the values of the various features for Honda and BMW. The \prog{featureInfo} function is supplied as an argument to the \prog{gather} function. \prog{feature} and \prog{featureF} are the same object maps constructed in different ways.
% \begin{haskellcode}
% featureInfo :: Feature -> Spread Car
% featureInfo x 
%     = case x of Price -> [Honda --> 24000,BMW --> 36000]
%                 Safety -> [Honda --> 30,BMW --> 70]
%                 Fuel   -> [Honda --> 36,BMW --> 24]

% features :: Obj Car Feature
% features = gather featureInfo
% \end{haskellcode}

% Suppose at some point we want to add another brand say Toyota amongst the brand of cars under consideration for buying. This is achieved using an \prog{addAlternative} function. It takes as input the object to be appended to the object map, a map showing the values of the various attributes for the given object, and the object to be amended. The amended object map consists of the new object with its different attributes and attribute values.
% \begin{haskellcode}
% addAlternative :: (Ord o,Ord a) => o -> (a -> Double) -> Obj o a -> Obj o a
% addAlternative o f vs = Obj $ M.insert o (mkAttr ls) (unObj vs)
%     where ls = map (\x -> (x,f x)) members
% \end{haskellcode}
% To amend our example to consist of Toyota as well, we simply amend the car data type to add the Toyota constructor and create a function \prog{toyotaAttributes} specifying the value of the various attributes for Toyota. We finally use the \prog{addAlternative} function to add the Toyota alternative with its different attribute values stored in \prog{toyotaAttributes} to the already existing object map \prog{features} of Honda and BMW.
% \begin{haskellcode}
% data Car = Honda | BMW | Toyota 

% toyotaAttributes :: Feature -> Double
% toyotaAttributes x = case x of
%         Price  -> 20000
%         Safety -> 50
%         Fuel   -> 30

% features2 :: Obj Car Feature
% features2 = addAlternative Toyota toyotaAttributes features

% *Car> features2
% {Honda -> {Price -> 24000,Fuel -> 36,Safety -> 30},
%  BMW -> {Price -> 36000,Fuel -> 24,Safety -> 70},
%  Toyota -> {Price -> 20000,Fuel -> 30,Safety -> 50}}
%  \end{haskellcode}
 
% We can also delete an attribute from an already existing object map using the \prog{delAttribute} function. The function goes through every object of the object map sequentially and removes the speicified attribute from the attribute map associated with each object.
% \begin{haskellcode}
% delAttribute :: (Ord o,Ord a) => Obj o a -> a -> Obj o a
% delAttribute os a = mkObj [(o,f a ov) | (o,ov) <- fromObj os]
%         where f x xs = Attr $ M.delete x (unAttr xs)
                               
% featuresD = delAttribute features Price
% *Car> featuresD
% {Honda ->  {Fuel -> 36,Safety -> 30},
%  BMW -> {Fuel -> 24,Safety -> 70}}
% \end{haskellcode}

% We can also modify the value of an attribute for an object in an existing object map with the \prog{modAttribute} function as shown below.
% \begin{haskellcode}
% modAttribute :: (Ord a,Ord o) => Obj o a -> a -> o -> Double ->  Obj o a
% modAttribute os a o' v 
%     = mkObj [if o == o' then f a o v  ov else p | p@(o,ov) <- fromObj os]
%     where f a o v ov = (o,Attr $ M.insert a v (M.delete a (unAttr ov)))

% featuresM = modAttribute features Price Honda 45000
% \end{haskellcode}

\subsection{Normalizing Object Values}
The different attributes in an object mapping are measured in different units thereby making any sort of comparison between them difficult. We introduce the concept of normalization here using which we can go from absolute values of various attributes expressed in terms of their respective units to unit-less relative values between 0 and 1. 

The normalization process depends on the ``valency" of an attribute, that is whether the attribute is beneficial (positive) or non-beneficial (negative). As the name suggests, for a beneficial attribute like fuel efficiency (measured in say miles/gallon) a higher numerical value is desirable and a lower value is desirable for non-beneficial attributes like price. We define a type class \prog{AttrValence} which implements the \prog{valence} function. The \prog{valence} function specifies the valency of various attributes at a given level as demonstrated by the \prog{AttrValence} instance declaration of the \prog{Feature} data type shown below. 
\begin{haskellcode}
data Valence = Pos | Neg

class Ord a => AttrValence a where
   valence :: a -> Valence
   valence _ = Pos

instance AttrValence Feature where
   valence Price  = Neg
   valence Fuel   = Pos
   valence Safety = Pos
\end{haskellcode}
Now we define the \prog{normalize} function which implements the normalization process for an attribute. It takes as input the attribute to be normalized, and a list of the value corresponding to this attribute for the various objects. It uses the \prog{valence} function to access the valency of the attribute. If the attribute has a positive valency then we divide every value in the list by the sum of all the values in the list. In the case of negative valency attribute, to get a normalized value, the reciprocal of the original value is divided by sum of reciprocals of all the values in the list. An important point to note is that normalized values produced as output sum to 1. 
\begin{haskellcode}
normalize :: AttrValence a => a -> Spread o -> Spread o
normalize c as = let vs = [v | (_,v) <- as]
                     s = sum vs
                     s' = sum.map (\x -> 1/x) $ vs 
                 in case valence c of
                        Pos -> [(a,v/(sum vs)) | (a,v) <- as]
                        Neg -> [(a,(1/v)/s') | (a,v) <- as]
\end{haskellcode}
For example, the normalized values of the car prices for the three car are shown below. Since, price is a negative valency feature the cheapest car is assigned the highest value by the normalization process indicating its high desirability.
\begin{haskellcode}
*Car> normalize Price [(Honda,24000),(BMW,36000),(Toyota,20000)]
[(Honda,0.349),(BMW,0.233),(Toyota,0.419)]
\end{haskellcode}
\prog{Val o a} is a type synonym for \prog{Obj o a}. However, we use \prog{Val o a} to represent a normalized object mapping instead of \prog{Obj o a} which represents the unnormalized object mappings. The transformation from \prog{Obj o a} to \prog{Val o a} is achieved using a function called \prog{valuation} which uses the \prog{normalize} function to achieve normalization.
\begin{haskellcode}
*Car> valuation features2
{Honda -> {Price -> 0.349,Fuel -> 0.400,Safety -> 0.200},
 BMW -> {Price -> 0.233,Fuel -> 0.267,Safety -> 0.467},
 Toyota -> {Price -> 0.419,Fuel -> 0.333,Safety -> 0.333}}
\end{haskellcode}

\NOTE{The valuation function is too complicated to show here. Simplify it. }

\subsection{Combining Object Mappings}
We generate the object mappings between all the adjacent levels of the AHP diagram. That is, we have the object mappings of these types: \prog{Obj Car Feature}, \prog{Obj Feature User}, and \prog{Obj User Weight}. We saw the construction of the object map of \prog{Obj Car Feature} in the previous section. The construction of \prog{Obj Feature User} and \prog{Obj User Weight} are shown below.
\begin{haskellcode}
userInfo :: User -> Spread Feature
userInfo x 
    = case x of 
        Friend -> [Price --> 0.5,Fuel --> 0.3,Safety --> 0.2]
        Expert -> [Price --> 0.2,Fuel --> 0.4,Safety --> 0.4]

users :: Obj Feature User
users = gather userInfo

weights :: Obj User Weight
weights = addAttribute Weight [Friend --> 0.6,Expert --> 0.4] objects
\end{haskellcode}
Once we have all the object maps, we can now combine to generate a final valuation of type \prog{Val Car (Feature,User,Weight)} We combine the valuation: The valuation \prog{Val Car Feature}, obtained by applying to \prog{valuation} function to the object map of type \prog{Obj Car Feature}, is combined with the object map with type \prog{Obj Feature User} and create a valuation \prog{Val Car (Feature,User)} which we in turn combine with the object map of \prog{Obj User Weight} which results in a final valuation of type \prog{Val Car (Feature,User,Weight)}. 

To recursively create these valuations we define a class \prog{ExtendVal} with the \prog{extendBy} function to combine a valuation and an object mapping and create a new valuation. 

\NOTE{Provide a brief description of the code shown below.}

% \begin{haskellcode}
% mkOneTuple :: (Ord o,Ord a) => Obj o a -> Obj o (OneTuple a)
% mkOneTuple = mkObj.map (\(o,a) -> (o,f a)).fromObj
%   where
%     f = mkAttr.map (\(b,n) -> (OneTuple b,n)).fromAttr

% class (Projector a b,Ord d,Ord o,Set b,AttrValence c) 
%       => ExtendVal o a b c d | a b c -> d where
%   mkTuple :: o -> (a,b,c) -> Double -> (o,(d,Double))

%   extendBy :: Val o a -> Obj b c -> Val o d
%   extendBy as bs
%     = mkVal [mkTuple o (aa,b,cc) (av*cv) 
%              |(o,a) <- fromObj as,(aa,av) <- fromAttr a,
%               (b,c) <- (fromObj.valuation) bs,
%               (cc,cv) <- fromAttr c, proj aa==b]

% instance (Set a,AttrValence b,Ord o) => 
%           ExtendVal o (OneTuple a) a b (a,b) where
%   mkTuple o (a,_,b) n = (o,((only a,b),n))

% instance (Set b,AttrValence c,Ord o,Ord a) => 
%           ExtendVal o (a,b) b c (a,b,c) where
%   mkTuple o ((a,b),_,c) n = (o,((a,b,c),n))

% \end{haskellcode}

Note that in the example below, we use the \prog{val} functions to perform two operations on the object value features: it performs a valuation of the object mapping and post that makes the attribute one element tuple.
\begin{haskellcode}
val :: (Set o,AttrValence a) => Obj o a -> Val o (OneTuple a)
val = mkOneTuple . valuation

cars :: Val Car (Feature,User,Weight)
cars = val features `extendBy` users `extendBy` weights

{Honda -> {(Price,Friend,Weight) -> 0.180,
           (Fuel,Friend,Weight) -> 0.108,
           (Safety,Friend,Weight) -> 0.036,
           (Price,Expert,Weight) -> 0.048,
           (Fuel,Expert,Weight) -> 0.096,
           (Safety,Expert,Weight) -> 0.048},
 BMW -> {(Price,Friend,Weight) -> 0.120,
         (Fuel,Friend,Weight) -> 0.072,
         (Safety,Friend,Weight) -> 0.084,
         (Price,Expert,Weight) -> 0.032,
         (Fuel,Expert,Weight) -> 0.064,
         (Safety,Expert,Weight) -> 0.112}}
\end{haskellcode}

The \prog{priority} function gets us the sum of all the individual attribute values corresponding to Honda or BMW thereby giving us the overall priority of cars.
\begin{haskellcode}
type Priority o = [(o,Fraction)]

carPriority :: Priority Car 
carPriority = priority cars

*Car> carPriority
[(Honda,0.516),(BMW,0.484)]
\end{haskellcode}
We can see that Honda pips out BMW with a higher priority value. However, since the priority values are close it may not be immediately apparent to the end user what attributes lead to the selection of Honda over BMW. We try answering this in next section. 

\subsection{Generating Explanation}
Once we have obtained the final valuation by combining all the object mappings, we can start generating explanations. The first step in generating the explanation for the car example involves selecting the relevant attributes for Honda and BMW. The \prog{select} function takes as input the final valuations for the car examples and filters the parts corresponding to Honda and BMW as can be seen below.
\begin{haskellcode}
type CarDecomp = Attr (Feature,User,Weight)

honda :: CarDecomp
honda = select Honda carsVal

bmw :: CarDecomp
bmw = select BMW carsVal

*Car> honda
{Honda -> {(Price,Friend,Weight) -> 0.180,
           (Fuel,Friend,Weight) -> 0.108,
           (Safety,Friend,Weight) -> 0.036,
           (Price,Expert,Weight) -> 0.048,
           (Fuel,Expert,Weight) -> 0.096,
           (Safety,Expert,Weight) -> 0.048}}
 
*Car> bmw
 {BMW -> {(Price,Friend,Weight) -> 0.120,
          (Fuel,Friend,Weight) -> 0.072,
          (Safety,Friend,Weight) -> 0.084,
          (Price,Expert,Weight) -> 0.032,
          (Fuel,Expert,Weight) -> 0.064,
          (Safety,Expert,Weight) -> 0.112}}
\end{haskellcode}
We express the various MDS concepts like value difference, support, barrier, dominators, MDS as type synonyms of the attribute map as shown below. Finally an explanation consists of a tuple of the value difference, the barrier, the list of all the dominators, and the list of all the MDS explanations. 
\begin{haskellcode}
type ValDiff a = Attr a 
type Barrier a = Attr a 
type Support a = Attr a 
type MDS a = Attr a
type Dom a = Attr a 
type Explain b = (ValDiff b,Support b,Barrier b,[Dom b],[MDS b])
\end{haskellcode}
The value difference (computed with the \prog{diff} function) between Honda and BMW provides us with a element wise comparison between Honda and BMW. 
\begin{haskellcode}
vdCar :: CarDecomp
vdCar = diff honda bmw

*Car> vdCar
{(Price,Friend,Weight) -> 0.060,
 (Fuel,Friend,Weight) -> 0.036,
 (Safety,Friend,Weight) -> -0.048,
 (Price,Expert,Weight) -> 0.016,
 (Fuel,Expert,Weight) -> 0.032,
 (Safety,Expert,Weight) -> -0.064}
\end{haskellcode}
We can see that friends and experts feel that Honda is better is terms of price and fuel efficiency. However, both feel that BMW is a safer car. As the overall priority of the cars suggests, that raving reviews for safety ratings are not enough to turn the tide in favour of BMW. We can use the MDS concepts to determine the minimal set of features that lead to the selection of Honda. We use the \prog{explain} function to use the generate this explanation and \prog{pmds} to print this explanation. It turns out that even if experts had been neutral (but not negative) about the price of Honda, it still would have pipped BMW. That is, price considerations by friends, and fuel efficiency considerations by both friends and experts is the minimal reason for why Honda was selected over BMW.
\begin{haskellcode}
exp0 :: Explain (Feature,User,Weight) 
exp0 = explain vdCar

*Car> pmds exp0

Value Difference: {(Price,Friend,Weight) -> 0.060,
                   (Fuel,Friend,Weight) -> 0.036,
                   (Safety,Friend,Weight) -> -0.048,
                   (Price,Expert,Weight) -> 0.016,
                   (Fuel,Expert,Weight) -> 0.032,
                   (Safety,Expert,Weight) -> -0.064}

Support: {(Price,Friend,Weight) -> 0.060,
          (Fuel,Friend,Weight) -> 0.036,
          (Price,Expert,Weight) -> 0.016,
          (Fuel,Expert,Weight) -> 0.032}

Barrier: {(Safety,Friend,Weight) -> -0.048,
          (Safety,Expert,Weight) -> -0.064}

MDS: {(Price,Friend,Weight) -> 0.060,
      (Fuel,Friend,Weight) -> 0.036,
      (Fuel,Expert,Weight) -> 0.032}
\end{haskellcode}

\subsection{Explanation Transformations}
The explanations generated thus far can be further improved by providing functionalities that transform these explanations and make them easier to understand.  

\subsection{Decluttering Explanations}\label{ReduceExpl}
To begin with we notice that the attribute \prog{Weight} remains constant throughout the explanation in the MDS explanation in \prog{exp0}. Removing it would enhance the readability of explanations. We use the \prog{reduce} function provided by the \prog{Reduce} type class to remove a constant attribute value from a multi-level attribute map. The element to be removed is selected by the type annotation accompanying the reduce function. The \prog{Reduce} class definition and its two instances corresponding to the tuple of three elements are shown below. The reduce function uses a helper function \prog{rmv}, another function provided by the \prog{Reduce} type class. The \prog{rmv} function removes an element from the tuple type based on type annotation. 
\begin{haskellcode}
class Reduce a b | a -> b where
  rmv :: a -> b 
  
  reduce :: (Ord a,Ord b) => Attr a -> Attr b 
  reduce = mkAttr.map (\(x,n) -> (rmv x,n)).fromAttr

instance Reduce (a,b,c) (b,c) where
  rmv :: (a,b,c) -> (b,c)
  rmv (a,b,c) = (b,c)

instance Reduce (a,b,c) (a,c) where
  rmv :: (a,b,c) -> (a,c)
  rmv (a,b,c) = (a,c)

instance Reduce (a,b,c) (a,b) where
  rmv :: (a,b,c) -> (a,b)
  rmv (a,b,c) = (a,b)
\end{haskellcode}
In the code shown below, we extract the MDS explanations from the explanation by pattern-matching on the complete explanation \prog{exp0} and select one of extracted MDS attributes using the \prog{head} function, and finally remove the \prog{Weight} attribute from the selected using the \prog{reduce} function. This transformed MDS explanation is finally bound to \prog{mds0}.
\begin{haskellcode}
mds0 :: MDS (User,Feature)
mds0 = let (_,_,_,ms,_) = exp0
       in  reduce (head ms)::Attr (User,Feature)
       
*Car> mds0
{(Price,Friend) -> 0.060,
 (Fuel,Friend) -> 0.036,
 (Fuel,Expert) -> 0.032}
\end{haskellcode}

\subsection{Factorizing Explanations}
The MDS explanations look a little less once they have been transformed with the \prog{reduce} function. However, parsing the significance of the individual attributes from the components of the MDS can be difficult. For example, in the \prog{mds0} explanation (Section \ref{ReduceExpl}) how do we understand the significance of the individual components. We could ask ``How does the opinion of friends compare against that of the experts in the decision to buy Honda over BMW?''. Similarly, we could ask ``How significant are the roles of the individual car features in the decision making process?''. We answer these fine grained questions about the MDS explanations using a function called \prog{factorize} provided by the \prog{GroupBy} type class which we describe in the next section. 

\subsubsection {The GroupBy type class}
Before we describe the design of the \prog{GroupBy} type class, we briefly discuss two of its superclasses, namely the \prog{Projector} and \prog{SumOut} type class. 

\prog{Projector a b} is a multi-parameter type class. The definition of the type class and its two instances for the pair type are shown below. The \prog{proj} function provided by the \prog{Projector} type class projects an element from a n-tuple based on the type annotation.
\begin{haskellcode}
class Projector a b | a -> b where
  proj :: a -> b 

instance Projector (a,b) a where
  proj = fst      

instance Projector (a,b) b where
  proj = snd
 
*Car> proj (Friend,Fuel) :: Feature
Fuel
*Car> proj (Friend,Fuel) :: User
Friend
\end{haskellcode}
\prog{SumOut a b} is again a multi-parameter type class which provides the \prog{sumOut} function that sums out the attributes corresponding to all but one level (the level corresponding to level \prog{b}) from \prog{Attr a}. For example, \prog{SumOut (a,b) b} singnifies that from the combined attribute maps of levels \prog{a} and \prog{b}, the attributes corresponding to type \prog{a} are summed out thereby generating a new attribute map entirely in terms of attributes of type \prog{b}. \prog{SumOut a b} is a sub-class of \prog{Projector a b}. Its type class definition and the two instances for the pair type are shown below. 
\begin{haskellcode}
class (Projector a b,Ord b) => SumOut a b | a -> b where
  sumOut :: Attr a -> Attr b 
  sumOut = mkAttr.map h.groupBy g.sortBy (compare `on` f).fromAttr
    where h xs = ((f.head) xs,(sum.map snd) xs)
          g x y = f x == f y
          f = proj.fst

instance Ord b => SumOut (a,b) b 
instance Ord a => SumOut (a,b) a 
\end{haskellcode}
In the first example shown below, the value difference between Honda and BMW is expressed entirely in terms of the \prog{User} attribute by summing out the other attributes from the value difference. Similarly, in the second example the same value difference is expressed in terms of the \prog{Feature} attributes.
\begin{haskellcode}
*Car> sumOut vdCar :: Attr User
{Friend -> 0.048,Expert -> -0.016}
 
*Car> sumOut vdCar :: Attr Feature
{Price -> 0.076,Fuel -> 0.068,Safety -> -0.112}
\end{haskellcode}

Factorization of an explanation extracts the individual contributions of attributes of a given level. It also shows how these contributions are synthesized. The level for which the contributions of the attributes is to be computed is conveyed by type annotation. The \prog{factorize} function sums out the attributes of all but the chosen level to get the contribution of attributes of the chosen level while also tracking how the individual components from the original attribute contribute.
\begin{haskellcode}
type Factor b c = [(b,Attr c,Double)]

class (SumOut a b,Reduce a c,Projector a b) => GroupBy a b c | a -> b c where 
  factorize :: (Ord a,Ord b,Ord c) => Attr a -> Factor b c
  factorize xs = zipWith (\x y -> (fst x,reduce y,snd x)) (h xs) (k xs)
      where h = sort.fromAttr.sumOut
            k = map mkAttr.groupBy g.sortBy (compare `on` f).fromAttr 
            g x y = f x == f y
            f = proj.fst 
\end{haskellcode}
For example, consider the MDS explanation for \prog{mds0} from Section \ref{ReduceExpl}. The factorized explanation for \prog{mds0} in terms of the \prog{Feature} level is shown below. \prog{pFact} function pretty prints the factorizations. The factorized representation answers to the question about the relative importance of the price and fuel attributes in the explanation for selecting Honda over BMW. Clearly price seems to be a more important factor than fuel in the decision making process.
\begin{haskellcode}
m01 = pFact (factorize mds0 :: Factor Feature User)

*Car> m01
Price : 0.060 ({Friend -> 0.060})
Fuel : 0.068 ({Friend -> 0.036,Expert -> 0.032})
\end{haskellcode}
Similarly, for the \prog{User} level, it turns out that friends had more of a say in tilting the scale in favour of Honda as compared to experts. 
\begin{haskellcode}
m02 = pFact (factorize mds0 :: Factor User Feature)

*Car> m02
Friend : 0.096 ({Price -> 0.060, Fuel -> 0.036})
Expert : 0.032 ({Fuel -> 0.032})
\end{haskellcode}

\subsection{Localizing Explanations}
We have tried making explanations easier to consume. However, the explanation terms (MDS explanations) involve features from various levels. The involvement of multiple levels makes it difficult for the end user to consume the explanation. Most human activities involve a complex interplay of various factors. It is not uncommon for us to untangle the complex interaction between the various factors and understand them one factor at a time. For example, the modern economy is a highly complex system and may depend on environmental factors like amount of rainfall, political factors like stability of the government in the country, and human/social factors like quality of labour force. It is not uncommon for economists/commentators to explain a certain economic event in terms of one factor. For example, the most popular explanation for 2008 financial crisis is the housing market collapse. 

The \emph{generalize} function provided by the type class \prog{Generalize} allows the end users to choose the level at which they seek explanation and provides the explanation at the selected level. In the context of the car example, this means that users can query ``Whose opinion prevailed in favoring Honda over BMW?''. Similarly, we can also ask ``What car features lead to the selection of Honda over BMW?''. 
\subsubsection{Type Class Generalize}

\prog{Generalize a b} is a multi-argument type class where type \prog{a} represents the value difference consisting of attribute values from all the levels and type \prog{b} represents the level at which explanation is desired. \prog{Generalize a b} is a sub-class of class The \prog{generalize} function uses \prog{sumOut} to amend the value difference in terms of attributes of level \prog{b} entirely and generates explanations for this amended value difference. \prog{Generalize a b} is a sub-class of \prog{SumOut a b}
\begin{haskellcode}
class (Ord a,Ord b,SumOut a b) => Generalize a b | a -> b where
    generalize :: ValDiff a -> Explain b
    generalize = explain.sumOut

instance (Ord a,Ord b) => Generalize (a,b) a 
instance (Ord a,Ord b) => Generalize (a,b) b 
\end{haskellcode}
The total value difference remains constant throughout the various levels: We simply redistribute the value difference in terms of the elements at that level using the \prog{sumOut} function.

% I think the redistribution operation (processing of summing out the attributes) is a valid operation and doesn't impact the correctness of the explanation process.

We see that at the level of users represented by \prog{exp1} in the code shown below, friends are the reason why Honda was selected over BMW. Similarly, at the level of features represented by \prog{exp2}, price and fuel are the reason why Honda was preferred. 
\begin{haskellcode}
exp1 :: Explain User
exp1 = generalize vdCar

*Car> pmds exp1
Value Difference: {Friend -> 0.048,Expert -> -0.016}

Support: {Friend -> 0.048}

Barrier: {Expert -> -0.016}

MDS: {Friend -> 0.048}

exp2 :: Explain Feature
exp2 = generalize vdCar

*Car> pmds exp2
Value Difference: {Price -> 0.076,Fuel -> 0.068,Safety -> -0.112}

Support: {Price -> 0.076,Fuel -> 0.068}

Barrier: {Safety -> -0.112}

MDS: {Price -> 0.076,Fuel -> 0.068}
\end{haskellcode}

\section{Case Study : Election Example}
We present another example here which elucidates the versatility of our DSL. This example pertains to explaining the result of presidential elections between Donald Trump and Hillary Clinton in 2016. Assume that before the elections a survey of the potential voters was conducted which tried to predict the potential outcome of the election along with the understanding the rationale for the choice of the voters. 

\tikzstyle{startstop} = []
\tikzstyle{arrow} = []
\begin{figure}[h]
    \centering
        \begin{tikzpicture}[node distance=1.2cm]
        level 1/.style={level distance=0.5cm}
        \node (total) [startstop] {Score};
        \node (rural) [startstop, below of = total, xshift = -1cm] {Rural} ;
        \node (urban) [startstop, right of = rural,xshift = 1cm] {Urban}; 
        \node (young) [startstop, below of = rural,  xshift = -1cm] {Young};
        \node (middleAged) [startstop, right of = young,  xshift = 0.7cm] {Middle Aged}; 
        \node (old) [startstop, right of = middleAged,xshift = 1.2cm] {Old};

        \node (economic) [startstop, below of = middleAged,  xshift = -1.1cm] {Economic}; 
        \node (environment) [startstop, left of = economic, xshift = -1cm] {Environment}; 
        \node (foreign) [startstop, right of = economic,xshift = 1cm] {Foreign};
        \node (health) [startstop, right of = foreign,xshift = 1cm] {Health};

        \node (clinton) [startstop, below of = economic] {Clinton}; 
        \node (trump) [startstop, right of = clinton,xshift = 1cm] {Trump};
        \draw [arrow] (total.south) -- (rural);
        \draw [arrow] (total.south) -- (urban);
        \draw [arrow] (rural.south) -- (young);
        \draw [arrow] (rural.south) -- (middleAged);
        \draw [arrow] (rural.south) -- (old);
        \draw [arrow] (urban.south) -- (young);
        \draw [arrow] (urban.south) -- (middleAged);
        \draw [arrow] (urban.south) -- (old);
        
        \draw [arrow] (young.south) -- (environment);
        \draw [arrow] (young.south) -- (economic);
        \draw [arrow] (young.south) -- (foreign);
        \draw [arrow] (young.south) -- (health);   
        
        \draw [arrow] (middleAged.south) -- (environment);
        \draw [arrow] (middleAged.south) -- (economic);
        \draw [arrow] (middleAged.south) -- (foreign);
        \draw [arrow] (middleAged.south) -- (health);   

        \draw [arrow] (old.south) -- (environment);
        \draw [arrow] (old.south) -- (economic);
        \draw [arrow] (old.south) -- (foreign);
        \draw [arrow] (old.south) -- (health);  


        \draw [arrow] (environment.south) -- (clinton);
        \draw [arrow] (economic.south) -- (clinton);
        \draw [arrow] (foreign.south) -- (clinton);
        \draw [arrow] (health.south) -- (clinton); 
        
        \draw [arrow] (environment.south) -- (trump);
        \draw [arrow] (economic.south) -- (trump);
        \draw [arrow] (foreign.south) -- (trump);
        \draw [arrow] (health.south) -- (trump); 
        \end{tikzpicture}
    \caption{AHP Model for Predicting the 2016 Presidential Election.}
    \label{AHP_Candidate}
\end{figure} 

The AHP model used for the problem is shown in Figure \ref{AHP_Candidate}. We assume that various factors affecting voters' choices are the geography of the areas they reside in that is whether they live in rural or urban areas, their age groups that is whether they are young, middle aged, or old, their policy leanings that is how to do they rate the importance of various policies like environment, economic, foreign, and health and finally the perception of the voters about how serious the two candidates are with regards to these policies. The Haskell data type representation of the various decision attributes is shown below.
\begin{haskellcode}
data Geography = Rural | Urban 
data Demography = Young | MiddleAged | Old 
data Policy = Environment | Economic | Foreign | Health 
data Candidate = Clinton | Trump 
data Population  = Population 
\end{haskellcode}
We begin by noting that 500 people are interviewed from rural and urban areas each for this opinion poll. This is encoded in Haskell in the \prog{populationInfo} distribution shown below. The object map for to the distribution is obtained using the \prog{gather} function also shown below. 
\begin{haskellcode}
populationInfo :: Population -> Spread Geography 
populationInfo Population = [Rural --> 500,Urban --> 500]

*Election> gather populationInfo
{Rural -> {Population -> 500.000},
 Urban -> {Population -> 500.000}}
\end{haskellcode}
Assume that the survey showed that the demography of rural areas is 20 \% youth, 30\% middle aged, and 50\% old. Similarly, demography of urban areas is 40\% youth, 40\% middle aged, and 20\% old. The demographic distribution of the rural and the urban areas and the corresponding object map is shown below. 
\begin{haskellcode}
geographyInfo :: Geography -> Spread Demography 
geographyInfo x = case x of
                      Rural -> [Young --> 100,MiddleAged --> 150,Old --> 250]
                      Urban -> [Young --> 200,MiddleAged --> 200,Old --> 100]
          
*Election> gather geographyInfo
{Young -> {Rural -> 100,Urban -> 200},
 MiddleAged -> {Rural -> 150,Urban -> 200},
 Old -> {Rural -> 250,Urban -> 100}}
\end{haskellcode}
The object map corresponding to \prog{geographyInfo} tells us that thereare  300 young voters in total with 100 of them in rural areas and 200 of them in urban areas. Similarly, we find that there are 350 each of middle aged and old voters in total. We can verify that this categorisation of voters also yields a total of 1000 voters, the number of voters that we started with.

Now each demography of voters expresses what policies are important to them. Assume that in young voters who are 300 in number, ${1/3}^{rd}$ (100) of them plan to vote based on a candidate's education policy, ${1/6}^{th}$ (50) each for economic and foreign policy, and the remaining ${1/3}^{rd}$ (100) for health policy. The distribution \prog{demographyInfo} shows a similar distribution for middle aged and old voters as well in addition to the young voters.
\begin{haskellcode}
demographyInfo :: Demography -> Spread Policy
demographyInfo x 
    = case x of
        Young -> [Environment --> 100,Economic --> 50,Foreign --> 50,Health --> 100]
        MiddleAged -> [Environment --> 75,Economic --> 125,Foreign --> 75,Health --> 75]
        Old -> [Environment --> 50,Economic --> 100,Foreign --> 50,Health --> 150]

*Election> gather demographyInfo
{Environment -> {Young -> 100,MiddleAged -> 75,Old -> 50},
 Economic -> {Young -> 50,MiddleAged -> 125,Old -> 100},
 Foreign -> {Young -> 50,MiddleAged -> 75,Old -> 50},
 Health -> {Young -> 100,MiddleAged -> 75,Old -> 150}}
\end{haskellcode}
We obtain the count of voters who voted for environment, economic, foreign, and health policies from the object map shown above which is 225, 275, 175, and 325 respectively. Finally, each of these four groups of voters are asked who amongst Clinton and Trump can implement the pertinent policies for their groups most effectively. For example, ${4/5}^{th}$ of the voters voting primarily on environment policies feel that Clinton is better person than Trump to legislate the policies they want implemented. The distribution for all the four policies are specified by the \prog{policyInfo} function shown below. 
\begin{haskellcode}
policyInfo :: Policy -> Spread Candidate
policyInfo x = case x of Environment-> [Clinton --> 180,Trump --> 45] 
                         Economic -> [Clinton --> 55,Trump --> 220]
                         Foreign  -> [Clinton --> 35,Trump --> 140]  
                         Health   -> [Clinton --> 195,Trump --> 130]
                         
*Election> gather policyInfo
{Clinton -> {Environment -> 180,Economic -> 55,Foreign -> 35,Health -> 195},
 Trump ->   {Environment -> 45,Economic -> 220,Foreign -> 140,Health -> 130}}
\end{haskellcode}
The object map shown above shows the breakup of voters voting for candidates based on their policy affiliations. We also find that Trump and Clinton received a total of 535 and 465 voted respectively which makes Trump the winner in the opinion polls. 

Once we have the distributions the various consecutive levels, we can compute the final valuation as shown below. The final valuation suggests that Trump has a higher chance of winning the elections than Clinton. 
\begin{haskellcode}
candidates :: Val Candidate (Policy,Demography,Geography,Population)
candidates = val' policyInfo `extend` demographyInfo `extend` geographyInfo 
             `extend` populationInfo

*Election> priority candidates
[(Clinton,0.465),(Trump,0.535)]
\end{haskellcode}

We can think of the priority scores of $0.535$ and $0.465$ for Trump and Clinton respectively as the normalized value the number of votes achieved by each of the candidate: $(535/(535 + 465) = 0.535)$ and $(465/(535 + 465) = 0.465)$. This intuition allows us a deeper understanding of the \prog{candidates} valuation shown below. We can multiply the values in the various rows in the valuation by 1000 which gives us a split of the votes in terms of the various geographies, demographics, and policies. For example, the first component of Clinton's valuation suggests that out of the 1000 voters who were polled, 27 $(0.027 \times 1000)$ rural young voters voted for Clinton's environment policies as compared to just 7 rural young voters who voted for Trumps' environmental policies. The difference is accentuated in the urban areas where Clinton's environmental policies garner a substantial 53 votes from the young population as compared to just 13 votes for Trump's policies in the same demography. 
\begin{haskellcode}
*Election> candidates
{Clinton -> {(Environment,Young,Rural,Population) -> 0.027,
             (Environment,Young,Urban,Population) -> 0.053,
                          ...
            },
 Trump -> {(Environment,Young,Rural,Population) -> 0.007,
           (Environment,Young,Urban,Population) -> 0.013,
                       ...
          }}
\end{haskellcode}

Once we have the valuation, we can separate the valuation components for Trump and Clinton and compute the valuation difference as shown below. We also remove the \prog{Population} constructor from the value difference as it remains constant through all the components of the value difference and doesn't add any useful information.
\begin{haskellcode}
type CandidateDecomp = Attr (Policy,Demography,Geography,Population)

trump :: CandidateDecomp
trump = select Trump candidates

clinton :: CandidateDecomp
clinton = select Clinton candidates

vdCandidate :: Attr (Policy,Demography,Geography)
vdCandidate = reduce $ diff trump clinton
\end{haskellcode}

\subsection{Detailed Explanations for the Election Results}
Once we compute the value difference, we can now start generating explanations. The campaign managers of the two candidates may want to know information like ``What policy of the candidates are popular and amongst which section of the electorate?" so that they can remedy the problematic areas and consolidate their areas  of strength. 

We know that the advantages for Trump (and the disadvantage for Clinton) is recorded in the support component of the explanation. Similarly, disadvantage for Trump (and advantage for Clinton) is recorded in the barrier component of the explanation. We pattern match on the explanation to extract support and barrier components as shown below.
\begin{haskellcode}
expCandidate :: Explain (Policy,Demography,Geography)
expCandidate = explain vdCandidate

(_,support,barrier,_,_) = expCandidate
\end{haskellcode}
Now to get the policies (and its breakup) where Trump is at an advantage, we could factorize the \prog{support} components with respect to policy and get the following. The factorized support component tells us that Trump's economic and foreign seem to be attracting voters. His economic policy seem to be especially popular amongst middle aged rural and urban population and old rural population. Middle aged rural and urban population seem to be strong supporters for his foreign policy as well in addition to the young urban and old rural population. 
\begin{haskellcode}
policyTrump = pFact (factorize support :: Factor Policy (Demography,Geography))

*Election> policyTrump
Economic : 0.165 ({(Young,Rural) -> 0.010,
                   (Young,Urban) -> 0.020,
                   (MiddleAged,Rural) -> 0.032,
                   (MiddleAged,Urban) -> 0.043,
                   (Old,Rural) -> 0.043,
                   (Old,Urban) -> 0.017})

Foreign : 0.105 ({(Young,Rural) -> 0.010,
                  (Young,Urban) -> 0.020,
                  (MiddleAged,Rural) -> 0.019,
                  (MiddleAged,Urban) -> 0.026,
                  (Old,Rural) -> 0.021,
                  (Old,Urban) -> 0.009})
\end{haskellcode}

We can do a similar analysis for Clinton as shown below. Note that the negative sign with the component values simply signifies the fact that these are barrier components. That is, they represent the attributes where Clinton has an advantage over Trump. We can see that Clinton's environment policies have a strong support amongst the young and middle aged urban population. She is clearly at an advantage with regards to the health policies but she manages to garner substantial support only from the old rural voters for this policy. The support from other for this policy is marginal. 
\begin{haskellcode}
policyClinton = pFact (factorize barrier :: Factor Policy (Demography,Geography))

*Election> policyClinton
Environment : -0.135 ({(Young,Rural) -> -0.020,
                       (Young,Urban) -> -0.040,
                       (MiddleAged,Rural) -> -0.019,
                       (MiddleAged,Urban) -> -0.026,
                       (Old,Rural) -> -0.021,
                       (Old,Urban) -> -0.009})

Health : -0.065 ({(Young,Rural) -> -0.007,
                  (Young,Urban) -> -0.013,
                  (MiddleAged,Rural) -> -0.006,
                  (MiddleAged,Urban) -> -0.009,
                  (Old,Rural) -> -0.021,
                  (Old,Urban) -> -0.009})
\end{haskellcode}

In this section we only show factorization with regards to policy and not elucidate factorizations with respect to geography or the demography. Generally, we determine the aptness of a factorization based on the tasks at hand and who the end user towards whom the explanation is aimed at. 

\subsection{Summary Explanations for Election Results}
In the last section we saw detailed explanation of election results. However, not everyone may need and want the explanation in such detail. For example, the news channels may simply want to know ``How did the geography/demography/policy impact the election of Trump over Clinton?''. That is, we want to localize the explanation provided to just one level.

We begin by explaining the impact of demography in the election. This explanation is encoded in \prog{expC1} as shown below. We observe that the young voters overall are against Trump whereas the middle aged and old voters are in his favour. The support by either of middle aged or old voters is enough to overcome the negative opinion of Trump amongst the young voters. Another thing to notice in the value difference information is the relatively strong support of Trump amongst the middle aged voters as 60 $(0.06 \times 1000 )$ more middle aged voters voted for Trump than Clinton in the opinion polls. 
\begin{haskellcode}
expDemography :: Explain Demography 
expDemography = generalize vdCandidate 

*Election> pmds expDemography

Value Difference: {Young -> -0.020,MiddleAged -> 0.060,Old -> 0.030}

Support: {MiddleAged -> 0.060,Old -> 0.030}

Barrier: {Young -> -0.020}

MDS: {MiddleAged -> 0.060}
     {Old -> 0.030}
\end{haskellcode}

To understand the impact of geographical divide on the election, We encode an explanation at the level of geography and bind it to \prog{expGeography} as shown below. It turns out that Trump wins both the rural and urban voters. There is no barrier here as no components of the value difference have negative values. This means that either of rural or urban geographies are MDS explanations for Trump's victory. This might be surprising given that initial distributions might suggest that Clinton is in stronger position in urban areas especially amongst the young voters. However, the explanation informs us that overall Trump comfortably wins the urban votes. 
\begin{haskellcode}
expGeography :: Explain Geography
expGeography = generalize vdCandidate 

*Election> pmds expGeography

Value Difference: {Rural -> 0.040,Urban -> 0.030}

Support: {Rural -> 0.040,Urban -> 0.030}

Barrier: {}

MDS: {Rural -> 0.040}
     {Urban -> 0.030}
\end{haskellcode}

Finally, to understand the impact of policies on the outcome of the election we encode the explanation at policy level and bind it to \prog{expPolicy} as shown below. The explanation at the policy level tell us that people preferred Clinton's environment and health policies to that of Trump's. However, it turns out that a strong backing of Trump's economic and foreign policy by the voters more than makes us for the negative perception he faces at the environment and health policy front. 
\begin{haskellcode}
expPolicy :: Explain Policy
expPolicy = generalize vdCandidate 

*Election> pmds expPolicy

Value Difference:
{Environment -> -0.135,Economic -> 0.165,Foreign -> 0.105,Health -> -0.065}

Support:
{Economic -> 0.165,Foreign -> 0.105}

Barrier:
{Environment -> -0.135,Health -> -0.065}

MDS:
{Economic -> 0.165,Foreign -> 0.105}
\end{haskellcode}

We have demonstrated in the section that our MDS explanation mechanism along with our DSL is flexible enough to generate explanations at varying degree of abstracting depending on the taks at hand and end users of the explanation. 

\section*{Acknowledgements}
This work is partially supported by DARPA under the grant N66001-17-2-4030 and by the National Science Foundation under the grant CCF-1717300.

% \bibliographystyle{jfplike}
% \bibliographystyle{jfp}
\bibliography{MADMReferences,References,explain,se,me}  % list here all the bibliographies that

\label{lastpage}

\end{document}
